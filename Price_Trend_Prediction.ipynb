{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Price Trend Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOQjyOFiwDiAGpdjcKDLGJw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/btiv/stock-trend-prediction/blob/master/Price_Trend_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp_TUsGCfcGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright 2020 Brendan Tivnan\n",
        "#\n",
        "# Copyright 2020 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#   http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPGwHfmsjbpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NOTICE: THIS FILE HAS BEEN MODIFIED BY Brendan Tivnan UNDER COMPLIANCE \n",
        "# WITH THE APACHE 2.0 LICENCE FROM THE ORIGINAL WORK OF THE COMPANY \n",
        "# Google LLC."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_8g2RRUk5tx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Run on TensorFlow 2.x\n",
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s4CR-XpfJUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Import relevant modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrN6pr1KBZMB",
        "colab_type": "text"
      },
      "source": [
        "the label will be the delta between the close and open price, a positive delta indicates an increase of price, a negative indicates a decrease. The features\n",
        "will be volume, stochastic oscillator, relative strength index and the \n",
        "aroon indicator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGtJvjlZgoAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data collection\n",
        "\n",
        "\n",
        "# get the price data for a given stock, IBM default\n",
        "\n",
        "price_data = pd.read_csv(\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=IBM&outputsize=full&apikey=ZRNIEDRNCDG5D4TZ&datatype=csv\")\n",
        "\n",
        "# compute the delta\n",
        "\n",
        "price_data[\"delta\"] = price_data[\"close\"] - price_data[\"open\"]\n",
        "\n",
        "# scale volume\n",
        "\n",
        "price_data[\"volume\"] = price_data[\"volume\"] / 100000\n",
        "\n",
        "# collect other feature data\n",
        "\n",
        "stoch_data = pd.read_csv(\"https://www.alphavantage.co/query?function=STOCH&symbol=IBM&interval=daily&apikey=ZRNIEDRNCDG5D4TZ&datatype=csv\")\n",
        "rsi_data = pd.read_csv(\"https://www.alphavantage.co/query?function=RSI&symbol=IBM&interval=daily&time_period=10&series_type=open&apikey=ZRNIEDRNCDG5D4TZ&datatype=csv\")\n",
        "aroon_data = pd.read_csv(\"https://www.alphavantage.co/query?function=AROON&symbol=IBM&interval=daily&time_period=14&apikey=ZRNIEDRNCDG5D4TZ&datatype=csv\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMSCgrEGNDAG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "69ddac25-b8fc-4704-9479-92b6849e8e43"
      },
      "source": [
        "# drop the first value to offset label and features\n",
        "stoch_data = stoch_data.iloc[1:]\n",
        "rsi_data = rsi_data.iloc[1:]\n",
        "aroon_data = aroon_data.iloc[1:]\n",
        "\n",
        "# add feature data to price data frame\n",
        "\n",
        "price_data[\"SlowD\"] = stoch_data[\"SlowD\"]\n",
        "price_data[\"SlowK\"] = stoch_data[\"SlowK\"]\n",
        "price_data[\"RSI\"] = rsi_data[\"RSI\"]\n",
        "price_data[\"AroonDown\"] = aroon_data[\"Aroon Down\"]\n",
        "price_data[\"AroonUp\"] = aroon_data[\"Aroon Up\"]\n",
        "\n",
        "# shift data up\n",
        "\n",
        "price_data[\"SlowD\"] = price_data[\"SlowD\"].shift(-1)\n",
        "price_data[\"SlowK\"] = price_data[\"SlowK\"].shift(-1)\n",
        "price_data[\"RSI\"] = price_data[\"RSI\"].shift(-1)\n",
        "price_data[\"AroonDown\"] = price_data[\"AroonDown\"].shift(-1)\n",
        "price_data[\"AroonUp\"] = price_data[\"AroonUp\"].shift(-1)\n",
        "\n",
        "# delete rows with empty cells\n",
        "\n",
        "price_data.dropna(subset=[\"SlowD\", \"SlowK\", \"RSI\", \"AroonDown\", \"AroonUp\"], inplace=True)\n",
        "\n",
        "#shuffle the examples and then split into training and test sets\n",
        "\n",
        "price_data = price_data.reindex(np.random.permutation(price_data.index))\n",
        "\n",
        "train_df = price_data.iloc[:4229, :]\n",
        "test_df = price_data.iloc[4229:5000, :]\n",
        "validation_df = price_data.iloc[5000:, :]\n",
        "\n",
        "print(train_df)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       timestamp    open    high  ...      RSI  AroonDown   AroonUp\n",
            "5107  2000-05-17  107.50  108.87  ...  41.9652    92.8571    0.0000\n",
            "2252  2011-09-22  168.33  169.97  ...  62.4767    50.0000  100.0000\n",
            "3684  2006-01-17   82.80   83.16  ...  45.7080    42.8571   64.2857\n",
            "4464  2002-12-10   78.60   81.00  ...  44.9391     7.1429   64.2857\n",
            "1998  2012-09-25  205.60  207.32  ...  58.8304     0.0000   64.2857\n",
            "...          ...     ...     ...  ...      ...        ...       ...\n",
            "3248  2007-10-10  118.00  118.80  ...  57.2595    78.5714   64.2857\n",
            "2202  2011-12-02  189.92  191.33  ...  58.5314    71.4286  100.0000\n",
            "883   2017-03-03  180.04  181.32  ...  63.1150     0.0000   35.7143\n",
            "2748  2009-10-05  118.90  120.18  ...  37.7586     0.0000   28.5714\n",
            "2174  2012-01-13  179.48  179.61  ...  39.1129   100.0000   50.0000\n",
            "\n",
            "[4229 rows x 12 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya1OXpCgFyPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an empty list that will eventually hold all feature columns.\n",
        "feature_columns = []\n",
        "\n",
        "# Create a numerical feature column to represent volume.\n",
        "volume = tf.feature_column.numeric_column(\"volume\")\n",
        "feature_columns.append(volume)\n",
        "\n",
        "# Create a numerical feature column to represent SlowD.\n",
        "slowd = tf.feature_column.numeric_column(\"SlowD\")\n",
        "feature_columns.append(slowd)\n",
        "\n",
        "# Create a numerical feature column to represent SlowK.\n",
        "slowk = tf.feature_column.numeric_column(\"SlowK\")\n",
        "feature_columns.append(slowk)\n",
        "\n",
        "# Create a numerical feature column to represent RSI.\n",
        "rsi = tf.feature_column.numeric_column(\"RSI\")\n",
        "feature_columns.append(rsi)\n",
        "\n",
        "# Create a numerical feature column to represent Aroon Down.\n",
        "aroon_down = tf.feature_column.numeric_column(\"AroonDown\")\n",
        "feature_columns.append(aroon_down)\n",
        "\n",
        "# Create a numerical feature column to represent Aroon Up.\n",
        "aroon_up = tf.feature_column.numeric_column(\"AroonUp\")\n",
        "feature_columns.append(aroon_up)\n",
        "\n",
        "# Convert the list of feature columns into a layer that will ultimately become\n",
        "# part of the model. Understanding layers is not important right now.\n",
        "my_feature_layer = layers.DenseFeatures(feature_columns)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F61fo7SkH6JW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5165e52b-78c1-40b8-b833-69d183fd48a4"
      },
      "source": [
        "#@title Define the plotting function.\n",
        "\n",
        "def plot_the_loss_curve(epochs, rmse):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Root Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs, rmse, label=\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.ylim([rmse.min()*0.95, rmse.max() * 1.03])\n",
        "  plt.show()  \n",
        "\n",
        "print(\"Defined the plot_the_loss_curve function.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined the plot_the_loss_curve function.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLJU9Wb1H7AU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(my_learning_rate, my_feature_layer):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Most simple tf.keras models are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Add the layer containing the feature columns to the model.\n",
        "  model.add(my_feature_layer)\n",
        "\n",
        "  # Describe the topography of the model by calling the tf.keras.layers.Dense\n",
        "  # method once for each layer. We've specified the following arguments:\n",
        "  #   * units specifies the number of nodes in this layer.\n",
        "  #   * activation specifies the activation function (Rectified Linear Unit).\n",
        "  #   * name is just a string that can be useful when debugging.\n",
        "\n",
        "  # Define the first hidden layer with 12 nodes.   \n",
        "  model.add(tf.keras.layers.Dense(units=12, \n",
        "                                  activation='relu', \n",
        "                                  name='Hidden1'))\n",
        "  \n",
        "  # Define the second hidden layer with 20 nodes. \n",
        "  model.add(tf.keras.layers.Dense(units=20, \n",
        "                                  activation='relu',\n",
        "                                  kernel_regularizer=tf.keras.regularizers.l2(l=0.1), \n",
        "                                  name='Hidden2'))\n",
        "  \n",
        "  # Define the third hidden layer with 64 nodes. \n",
        "  model.add(tf.keras.layers.Dense(units=64, \n",
        "                                  activation='relu',\n",
        "                                  kernel_regularizer=tf.keras.regularizers.l2(l=0.2), \n",
        "                                  name='Hidden3'))\n",
        "  \n",
        "  # Define the fourth hidden layer with 64 nodes. \n",
        "  model.add(tf.keras.layers.Dense(units=256, \n",
        "                                  activation='relu',\n",
        "                                  kernel_regularizer=tf.keras.regularizers.l2(l=0.3), \n",
        "                                  name='Hidden4'))\n",
        "\n",
        "  # Define the output layer.\n",
        "  model.add(tf.keras.layers.Dense(units=1,  \n",
        "                                  name='Output'))                              \n",
        "  \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGowuMCxxWgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, dataset, epochs, label_name,\n",
        "                batch_size=None):\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "  # Split the dataset into features and label.\n",
        "  features = {name:np.array(value) for name, value in dataset.items()}\n",
        "  label = np.array(features.pop(label_name))\n",
        "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
        "                      epochs=epochs, shuffle=True) \n",
        "\n",
        "  # The list of epochs is stored separately from the rest of history.\n",
        "  epochs = history.epoch\n",
        "  \n",
        "  # To track the progression of training, gather a snapshot\n",
        "  # of the model's mean squared error at each epoch. \n",
        "  hist = pd.DataFrame(history.history)\n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return epochs, rmse"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88mee_h-IK0Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "38faa063-239b-4a46-8627-1279fbe71ce2"
      },
      "source": [
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.001\n",
        "epochs = 500\n",
        "batch_size = 100\n",
        "label_name = \"delta\"\n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(learning_rate, my_feature_layer)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "epochs, rmse = train_model(my_model, train_df, epochs, label_name, batch_size)\n",
        "plot_the_loss_curve(epochs, rmse)\n",
        "\n",
        "test_features = {name:np.array(value) for name, value in test_df.items()}\n",
        "test_label = np.array(test_features.pop(label_name)) # isolate the label\n",
        "print(\"\\n Evaluate the linear regression model against the test set:\")\n",
        "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'timestamp': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'open': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'high': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'low': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'close': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'volume': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float32>, 'SlowD': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'SlowK': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'RSI': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'AroonDown': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'AroonUp': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'timestamp': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'open': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'high': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'low': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'close': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'volume': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float32>, 'SlowD': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'SlowK': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'RSI': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'AroonDown': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'AroonUp': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 32.6358 - root_mean_squared_error: 1.7352\n",
            "Epoch 2/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 19.5687 - root_mean_squared_error: 1.5581\n",
            "Epoch 3/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 13.4261 - root_mean_squared_error: 1.5666\n",
            "Epoch 4/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 10.3251 - root_mean_squared_error: 1.5813\n",
            "Epoch 5/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 8.4885 - root_mean_squared_error: 1.5675\n",
            "Epoch 6/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 7.2826 - root_mean_squared_error: 1.5591\n",
            "Epoch 7/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 6.3929 - root_mean_squared_error: 1.5487\n",
            "Epoch 8/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 5.7350 - root_mean_squared_error: 1.5484\n",
            "Epoch 9/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 5.2105 - root_mean_squared_error: 1.5469\n",
            "Epoch 10/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 4.7690 - root_mean_squared_error: 1.5407\n",
            "Epoch 11/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 4.4271 - root_mean_squared_error: 1.5418\n",
            "Epoch 12/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 4.1423 - root_mean_squared_error: 1.5427\n",
            "Epoch 13/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 3.8887 - root_mean_squared_error: 1.5382\n",
            "Epoch 14/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 3.6878 - root_mean_squared_error: 1.5390\n",
            "Epoch 15/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 3.5275 - root_mean_squared_error: 1.5434\n",
            "Epoch 16/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 3.3714 - root_mean_squared_error: 1.5407\n",
            "Epoch 17/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 3.2468 - root_mean_squared_error: 1.5414\n",
            "Epoch 18/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 3.1239 - root_mean_squared_error: 1.5376\n",
            "Epoch 19/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 3.0294 - root_mean_squared_error: 1.5377\n",
            "Epoch 20/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.9541 - root_mean_squared_error: 1.5400\n",
            "Epoch 21/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.8775 - root_mean_squared_error: 1.5379\n",
            "Epoch 22/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.8191 - root_mean_squared_error: 1.5390\n",
            "Epoch 23/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.7623 - root_mean_squared_error: 1.5384\n",
            "Epoch 24/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.7186 - root_mean_squared_error: 1.5396\n",
            "Epoch 25/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.6800 - root_mean_squared_error: 1.5404\n",
            "Epoch 26/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.6386 - root_mean_squared_error: 1.5388\n",
            "Epoch 27/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.6099 - root_mean_squared_error: 1.5399\n",
            "Epoch 28/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.5828 - root_mean_squared_error: 1.5400\n",
            "Epoch 29/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.5579 - root_mean_squared_error: 1.5397\n",
            "Epoch 30/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.5350 - root_mean_squared_error: 1.5389\n",
            "Epoch 31/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.5149 - root_mean_squared_error: 1.5390\n",
            "Epoch 32/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.4982 - root_mean_squared_error: 1.5391\n",
            "Epoch 33/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.4856 - root_mean_squared_error: 1.5398\n",
            "Epoch 34/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.4728 - root_mean_squared_error: 1.5401\n",
            "Epoch 35/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.4587 - root_mean_squared_error: 1.5392\n",
            "Epoch 36/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.4500 - root_mean_squared_error: 1.5395\n",
            "Epoch 37/500\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 2.4410 - root_mean_squared_error: 1.5395\n",
            "Epoch 38/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.4347 - root_mean_squared_error: 1.5399\n",
            "Epoch 39/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.4264 - root_mean_squared_error: 1.5394\n",
            "Epoch 40/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.4212 - root_mean_squared_error: 1.5397\n",
            "Epoch 41/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.4162 - root_mean_squared_error: 1.5399\n",
            "Epoch 42/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.4111 - root_mean_squared_error: 1.5397\n",
            "Epoch 43/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.4070 - root_mean_squared_error: 1.5399\n",
            "Epoch 44/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.4032 - root_mean_squared_error: 1.5398\n",
            "Epoch 45/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.4000 - root_mean_squared_error: 1.5398\n",
            "Epoch 46/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3978 - root_mean_squared_error: 1.5400\n",
            "Epoch 47/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3949 - root_mean_squared_error: 1.5400\n",
            "Epoch 48/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3925 - root_mean_squared_error: 1.5399\n",
            "Epoch 49/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3907 - root_mean_squared_error: 1.5401\n",
            "Epoch 50/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3889 - root_mean_squared_error: 1.5402\n",
            "Epoch 51/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3874 - root_mean_squared_error: 1.5402\n",
            "Epoch 52/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3857 - root_mean_squared_error: 1.5402\n",
            "Epoch 53/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3847 - root_mean_squared_error: 1.5403\n",
            "Epoch 54/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3831 - root_mean_squared_error: 1.5402\n",
            "Epoch 55/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3822 - root_mean_squared_error: 1.5403\n",
            "Epoch 56/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3812 - root_mean_squared_error: 1.5404\n",
            "Epoch 57/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3803 - root_mean_squared_error: 1.5404\n",
            "Epoch 58/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3794 - root_mean_squared_error: 1.5403\n",
            "Epoch 59/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3786 - root_mean_squared_error: 1.5403\n",
            "Epoch 60/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3787 - root_mean_squared_error: 1.5406\n",
            "Epoch 61/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3781 - root_mean_squared_error: 1.5406\n",
            "Epoch 62/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3775 - root_mean_squared_error: 1.5406\n",
            "Epoch 63/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3766 - root_mean_squared_error: 1.5404\n",
            "Epoch 64/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3763 - root_mean_squared_error: 1.5404\n",
            "Epoch 65/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3761 - root_mean_squared_error: 1.5405\n",
            "Epoch 66/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3754 - root_mean_squared_error: 1.5404\n",
            "Epoch 67/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3748 - root_mean_squared_error: 1.5403\n",
            "Epoch 68/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3749 - root_mean_squared_error: 1.5404\n",
            "Epoch 69/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3747 - root_mean_squared_error: 1.5404\n",
            "Epoch 70/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3744 - root_mean_squared_error: 1.5404\n",
            "Epoch 71/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3745 - root_mean_squared_error: 1.5405\n",
            "Epoch 72/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3739 - root_mean_squared_error: 1.5403\n",
            "Epoch 73/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3742 - root_mean_squared_error: 1.5405\n",
            "Epoch 74/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3739 - root_mean_squared_error: 1.5404\n",
            "Epoch 75/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3741 - root_mean_squared_error: 1.5405\n",
            "Epoch 76/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3739 - root_mean_squared_error: 1.5405\n",
            "Epoch 77/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3739 - root_mean_squared_error: 1.5405\n",
            "Epoch 78/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3734 - root_mean_squared_error: 1.5404\n",
            "Epoch 79/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3737 - root_mean_squared_error: 1.5405\n",
            "Epoch 80/500\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 2.3734 - root_mean_squared_error: 1.5404\n",
            "Epoch 81/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3738 - root_mean_squared_error: 1.5406\n",
            "Epoch 82/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3739 - root_mean_squared_error: 1.5406\n",
            "Epoch 83/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3734 - root_mean_squared_error: 1.5404\n",
            "Epoch 84/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3731 - root_mean_squared_error: 1.5404\n",
            "Epoch 85/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3733 - root_mean_squared_error: 1.5404\n",
            "Epoch 86/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3731 - root_mean_squared_error: 1.5404\n",
            "Epoch 87/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3731 - root_mean_squared_error: 1.5404\n",
            "Epoch 88/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3731 - root_mean_squared_error: 1.5404\n",
            "Epoch 89/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3735 - root_mean_squared_error: 1.5406\n",
            "Epoch 90/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 91/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3734 - root_mean_squared_error: 1.5405\n",
            "Epoch 92/500\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 2.3730 - root_mean_squared_error: 1.5404\n",
            "Epoch 93/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3734 - root_mean_squared_error: 1.5406\n",
            "Epoch 94/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3740 - root_mean_squared_error: 1.5407\n",
            "Epoch 95/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3732 - root_mean_squared_error: 1.5405\n",
            "Epoch 96/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 97/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3732 - root_mean_squared_error: 1.5405\n",
            "Epoch 98/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 99/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 100/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3732 - root_mean_squared_error: 1.5405\n",
            "Epoch 101/500\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 2.3734 - root_mean_squared_error: 1.5406\n",
            "Epoch 102/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3731 - root_mean_squared_error: 1.5405\n",
            "Epoch 103/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 104/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 105/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3730 - root_mean_squared_error: 1.5404\n",
            "Epoch 106/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3733 - root_mean_squared_error: 1.5406\n",
            "Epoch 107/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3736 - root_mean_squared_error: 1.5407\n",
            "Epoch 108/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 109/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 110/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3733 - root_mean_squared_error: 1.5406\n",
            "Epoch 111/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3734 - root_mean_squared_error: 1.5406\n",
            "Epoch 112/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 113/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 114/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 115/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3730 - root_mean_squared_error: 1.5404\n",
            "Epoch 116/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3730 - root_mean_squared_error: 1.5404\n",
            "Epoch 117/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 118/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 119/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 120/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3732 - root_mean_squared_error: 1.5405\n",
            "Epoch 121/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 122/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 123/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 124/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 125/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3732 - root_mean_squared_error: 1.5405\n",
            "Epoch 126/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 127/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 128/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3730 - root_mean_squared_error: 1.5405\n",
            "Epoch 129/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3730 - root_mean_squared_error: 1.5404\n",
            "Epoch 130/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 131/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 132/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3736 - root_mean_squared_error: 1.5406\n",
            "Epoch 133/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3737 - root_mean_squared_error: 1.5407\n",
            "Epoch 134/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 135/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 136/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3730 - root_mean_squared_error: 1.5404\n",
            "Epoch 137/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 138/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 139/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 140/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 141/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3734 - root_mean_squared_error: 1.5406\n",
            "Epoch 142/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3733 - root_mean_squared_error: 1.5406\n",
            "Epoch 143/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3734 - root_mean_squared_error: 1.5406\n",
            "Epoch 144/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3724 - root_mean_squared_error: 1.5403\n",
            "Epoch 145/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 146/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 147/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 148/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3730 - root_mean_squared_error: 1.5405\n",
            "Epoch 149/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 150/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 151/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3737 - root_mean_squared_error: 1.5407\n",
            "Epoch 152/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 153/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3731 - root_mean_squared_error: 1.5405\n",
            "Epoch 154/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 155/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3734 - root_mean_squared_error: 1.5406\n",
            "Epoch 156/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 157/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 158/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3730 - root_mean_squared_error: 1.5404\n",
            "Epoch 159/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 160/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3731 - root_mean_squared_error: 1.5405\n",
            "Epoch 161/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3730 - root_mean_squared_error: 1.5404\n",
            "Epoch 162/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 163/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3730 - root_mean_squared_error: 1.5404\n",
            "Epoch 164/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3730 - root_mean_squared_error: 1.5405\n",
            "Epoch 165/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 166/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3736 - root_mean_squared_error: 1.5406\n",
            "Epoch 167/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 168/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 169/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 170/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 171/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 172/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 173/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 174/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 175/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3730 - root_mean_squared_error: 1.5405\n",
            "Epoch 176/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 177/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 178/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 179/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 180/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3734 - root_mean_squared_error: 1.5406\n",
            "Epoch 181/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3731 - root_mean_squared_error: 1.5405\n",
            "Epoch 182/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 183/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 184/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 185/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3730 - root_mean_squared_error: 1.5405\n",
            "Epoch 186/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 187/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 188/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3730 - root_mean_squared_error: 1.5404\n",
            "Epoch 189/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 190/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 191/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 192/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 193/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 194/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3733 - root_mean_squared_error: 1.5406\n",
            "Epoch 195/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 196/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 197/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 198/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 199/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3734 - root_mean_squared_error: 1.5406\n",
            "Epoch 200/500\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 2.3732 - root_mean_squared_error: 1.5405\n",
            "Epoch 201/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3737 - root_mean_squared_error: 1.5407\n",
            "Epoch 202/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 203/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 204/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 205/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 206/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 207/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3730 - root_mean_squared_error: 1.5405\n",
            "Epoch 208/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3730 - root_mean_squared_error: 1.5404\n",
            "Epoch 209/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 210/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 211/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 212/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3731 - root_mean_squared_error: 1.5405\n",
            "Epoch 213/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 214/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 215/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 216/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 217/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 218/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 219/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 220/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 221/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 222/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 223/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 224/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 225/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 226/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 227/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 228/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 229/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3731 - root_mean_squared_error: 1.5405\n",
            "Epoch 230/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 231/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 232/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 233/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 234/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 235/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 236/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 237/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3731 - root_mean_squared_error: 1.5405\n",
            "Epoch 238/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3733 - root_mean_squared_error: 1.5406\n",
            "Epoch 239/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3730 - root_mean_squared_error: 1.5404\n",
            "Epoch 240/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 241/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 242/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 243/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 244/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 245/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 246/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 247/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 248/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3730 - root_mean_squared_error: 1.5405\n",
            "Epoch 249/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 250/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 251/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 252/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 253/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 254/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 255/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 256/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 257/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 258/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 259/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3730 - root_mean_squared_error: 1.5405\n",
            "Epoch 260/500\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 261/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 262/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 263/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 264/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 265/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3731 - root_mean_squared_error: 1.5405\n",
            "Epoch 266/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 267/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 268/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 269/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 270/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 271/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 272/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 273/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 274/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 275/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 276/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 277/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 278/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 279/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 280/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 281/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 282/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 283/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 284/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3732 - root_mean_squared_error: 1.5405\n",
            "Epoch 285/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 286/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 287/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 288/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 289/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 290/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 291/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 292/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 293/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 294/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 295/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 296/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 297/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3735 - root_mean_squared_error: 1.5406\n",
            "Epoch 298/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3731 - root_mean_squared_error: 1.5405\n",
            "Epoch 299/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 300/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 301/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 302/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 303/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 304/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 305/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 306/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 307/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 308/500\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 309/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 310/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 311/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 312/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 313/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 314/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3730 - root_mean_squared_error: 1.5405\n",
            "Epoch 315/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 316/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 317/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 318/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 319/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 320/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 321/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 322/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3731 - root_mean_squared_error: 1.5405\n",
            "Epoch 323/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 324/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 325/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 326/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 327/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3731 - root_mean_squared_error: 1.5405\n",
            "Epoch 328/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 329/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 330/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 331/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 332/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 333/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 334/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 335/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 336/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 337/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 338/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 339/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 340/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 341/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 342/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 343/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 344/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 345/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 346/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 347/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 348/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 349/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 350/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 351/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 352/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 353/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 354/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 355/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 356/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 357/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 358/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 359/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 360/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 361/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 362/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 363/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 364/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 365/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 366/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 367/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 368/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 369/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 370/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 371/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 372/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 373/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 374/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 375/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 376/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 377/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 378/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 379/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 380/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 381/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 382/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 383/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 384/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 385/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 386/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3729 - root_mean_squared_error: 1.5404\n",
            "Epoch 387/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3730 - root_mean_squared_error: 1.5405\n",
            "Epoch 388/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 389/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 390/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 391/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 392/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 393/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 394/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 395/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 396/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 397/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 398/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 399/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 400/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 401/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 402/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 403/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 404/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 405/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 406/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 407/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 408/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 409/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 410/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 411/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3728 - root_mean_squared_error: 1.5404\n",
            "Epoch 412/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 413/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 414/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 415/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 416/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 417/500\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 418/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 419/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 420/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 421/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 422/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 423/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 424/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 425/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 426/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 427/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 428/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 429/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 430/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 431/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 432/500\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 433/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 434/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 435/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 436/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 437/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 438/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 439/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 440/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 441/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 442/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 443/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 444/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 445/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 446/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 447/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 448/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 449/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 450/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 451/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 452/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 453/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 454/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 455/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 456/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 457/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 458/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 459/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 460/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 461/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 462/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 463/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 464/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5403\n",
            "Epoch 465/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 466/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 467/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 468/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 469/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 470/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 471/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 472/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 473/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 474/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 475/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 476/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 477/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 478/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 479/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 480/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 481/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 482/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 483/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 484/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 485/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 486/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 487/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3724 - root_mean_squared_error: 1.5403\n",
            "Epoch 488/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 489/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 490/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 491/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 492/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 493/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3727 - root_mean_squared_error: 1.5404\n",
            "Epoch 494/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 495/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 496/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 497/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3726 - root_mean_squared_error: 1.5403\n",
            "Epoch 498/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 499/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n",
            "Epoch 500/500\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.3725 - root_mean_squared_error: 1.5403\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xkZX3n8c+3qqu75z4wMyIywEC8kEGHkbQIgTjgrmaIt2VlFZRIjHGi0dzIGjFZYclrTVSIQZCEoOGiJrhxBQVFQC5hQGNgkAEG0QUBpRGdC3Pr6elLVf3yxzk1U9N1uru6p6uqp/r7fr3q1VXPOVXn9/T0nF89l/McRQRmZmYj5VodgJmZTU9OEGZmlskJwszMMjlBmJlZJicIMzPL1NHqAKbS4sWLY9myZa0Ow8zsgPHggw9ujoglWdvaKkEsW7aMdevWtToMM7MDhqSfjrbNXUxmZpbJCcLMzDI5QZiZWaa2GoMwM5us4eFhent7GRgYaHUoDdHd3c3SpUspFAp1v8cJwswM6O3tZd68eSxbtgxJrQ5nSkUEW7Zsobe3l6OOOqru97mLycwMGBgYYNGiRW2XHAAksWjRogm3jpwgzMxS7ZgcKiZTNycIMzPL5ARhZjZNzJ07t9Uh7MMJwszMMjlBmJlNY+vXr+fEE09kxYoVnHHGGWzduhWAyy67jOXLl7NixQrOOussAO655x5WrlzJypUrefWrX83OnTv369ie5mpmNsJFNz/GD3++Y0o/c/lL5nPhW46d8Pve8573cPnll7Nq1SouuOACLrroIi699FI++clP8vTTT9PV1cW2bdsAuOSSS7jiiis4+eST6evro7u7e79idgvCzGya2r59O9u2bWPVqlUAnHvuuaxduxaAFStW8O53v5svf/nLdHQk3/VPPvlkzjvvPC677DK2bdu2p3yy3IIwMxthMt/0m+1b3/oWa9eu5eabb+YTn/gEjz76KOeffz5vetObuOWWWzj55JO57bbbOOaYYyZ9DLcgzMymqQULFnDQQQdx7733AvClL32JVatWUS6XefbZZznttNP41Kc+xfbt2+nr6+MnP/kJr3rVq/joRz/Ka17zGn70ox/t1/HdgjAzmyb6+/tZunTpntfnnXce1113HR/4wAfo7+/n6KOP5pprrqFUKnHOOeewfft2IoI/+qM/YuHChXz84x/n7rvvJpfLceyxx3L66afvVzxOEGZm00S5XM4s//73v19Tdt9999WUXX755VMaj7uYzMwskxOEmZllcoIwM0tFRKtDaJjJ1K1hCULS1ZI2StowyvaPSFqfPjZIKkk6ON32jKRH023rGhWjmVlFd3c3W7ZsacskUbkfxEQvnGvkIPW1wOeAL2ZtjIiLgYsBJL0F+NOIeKFql9MiYnMD4zMz22Pp0qX09vayadOmVofSEJU7yk1EwxJERKyVtKzO3c8Grm9ULGZm4ykUChO629pM0PIxCEmzgdXA16qKA7hd0oOS1ozz/jWS1kla166Z38ysFVqeIIC3AN8d0b10SkQcD5wOfEjS60Z7c0RcFRE9EdGzZMmSRsdqZjZjTIcEcRYjupci4rn050bgRuCEFsRlZjajtTRBSFoArAK+UVU2R9K8ynPgjUDmTCgzM2uchg1SS7oeOBVYLKkXuBAoAETEleluZwC3R8SuqrceAtyY3mC7A/iXiLi1UXGamVm2Rs5iOruOfa4lmQ5bXfYUcFxjojIzs3pNhzEIMzObhpwgzMwskxOEmZllcoIAfu+6B7j+/p+1Ogwzs2nFCQL47pNbeHrzrvF3NDObQZwgAAnK5fZbwdHMbH84QQAiWfzJzMz2coIAchJtuAS8mdl+cYIAEJSdIczM9uEEQdLFZGZm+3KCAHI5teVtBs3M9ocTBEkLwpOYzMz25QQBSCI8j8nMbB9OEEBOeBaTmdkIThAAyF1MZmYjOEGQXEntS+XMzPblBIG7mMzMsoyZICTlJV3SrGBaRcgXypmZjTBmgoiIEnBKk2JpGbkFYWZWo557Uj8k6Sbgq8CeNbEj4oaGRdVkOckjEGZmI9STILqBLcDrq8oCaJsEAV6LycxspHETRES8txmBtJK83reZWY1xZzFJWirpRkkb08fXJC1tRnDN4i4mM7Na9UxzvQa4CXhJ+rg5LWsb8nLfZmY16kkQSyLimogopo9rgSXjvUnS1WmLY8Mo2z8iaX362CCpJOngdNtqST+W9KSk8ydUo0kQnsVkZjZSPQlii6Rz0msi8pLOIRm0Hs+1wOrRNkbExRGxMiJWAh8D7omIFyTlgSuA04HlwNmSltdxvElzF5OZWa16EsTvAu8AfgE8D5wJjDtwHRFrgRfqjONs4Pr0+QnAkxHxVEQMAV8B3lbn50yOu5jMzGqMOYsp/Tb/1xHx1kYFIGk2SUvjw2nRYcCzVbv0Aq8d4/1rgDUARxxxxORiAM9iMjMboZ4rqY+U1NnAGN4CfDci6m1t7CMiroqInojoWbJk3KGRTDnfD8LMrEY9F8o9BXw3vZq6+krqz0xRDGext3sJ4Dng8KrXS9OyhpGgXG7kEczMDjz1JIifpI8cMG8qDy5pAbAKOKeq+AHgZZKOIkkMZwHvmsrj1sSBWxBmZiPVMwbx8oh490Q/WNL1wKnAYkm9wIVAASAirkx3OwO4PSKqWyZFSR8GbgPywNUR8dhEjz+xWD3N1cxspDETRESUJB0pqTOdUVS3iDi7jn2uJZkOO7L8FuCWiRxvf8jTXM3MakyHMYiWSy6Uc4owM6vW0jGI6cJdTGZmtepZzfWikWWS6kksBwxfSW1mVmvU6yAk3Vf1/EsjNt/fsIhawIv1mZnVGutCuTlVz185YpsaEEvLeLE+M7NaYyWIGOV51usDmmcxmZnVGmssYaGkM0iSyEJJ/z0tF7Cg4ZE1UTJI7RRhZlZtrARxD/DWqudvqdq2tmERtYC7mMzMao2aIGbCvagrvFifmVmteu4H0fa8WJ+ZWS0nCLxYn5lZFicIfCW1mVmWUccgqmYtZYqIG6Y+nNZwF5OZWa2xZjFVZi29CPh14K709WnA94D2SRCIwBnCzKzauLOYJN0OLI+I59PXh5KxRPeBLJeDKLU6CjOz6aWeMYjDK8kh9UvgiAbF0xJCXovJzGyEelZlvVPSbey9b/Q7gTsaF1LzSW22doiZ2RSoZ7nvD6dLbrwuLboqIm5sbFjNJcmzmMzMRqj3vg4/AHZGxB2SZkuaFxE7GxlYM/mOcmZmtcYdg5D0fuD/Af+YFh0GfL2RQTWbu5jMzGrVM0j9IeBkYAdARDxBMvW1beTcxWRmVqOeBDEYEUOVF+ntRtvqdCp8Rzkzs5HqSRD3SPoLYJakNwBfBW5ubFjN5aU2zMxq1ZMgPgpsAh4Ffh+4BfhfjQyq2XxHOTOzWmPOYpKUBx6LiGOAzzcnpObzLCYzs1pjtiAiogT8WNKEr5yWdLWkjZI2jLHPqZLWS3pM0j1V5c9IejTdtm6ix554rO5iMjMbqZ7rIA4CHpN0P7CrUhgRbx39LUCyXtPngC9mbZS0EPh7YHVE/EzSyJlRp0XE5jri22++o5yZWa16EsTHJ/PBEbFW0rIxdnkXcENE/Czdf+NkjjMVJCg7P5iZ7aOepTbuGW+fSXo5UJD0b8A84LMRUWltBHC7pAD+MSKuGu1DJK0B1gAcccTk1hAU8hiEmdkI9VxJfaKkByT1SRqSVJK0YwqO3QH8GvAm4DeBj0t6ebrtlIg4Hjgd+JCk143yGUTEVRHRExE9S5YsmVwkvpLazKxGPdNcPwecDTwBzAJ+D7hiCo7dC9wWEbvSsYa1wHEAEfFc+nMjcCNwwhQcb1Q5r7VhZlajrntSR8STQD4iShFxDbB6Co79DeAUSR2SZgOvBR6XNEfSPABJc4A3AqPOhJoKvpLazKxWPYPU/ZI6gfWSPg08T31dU9cDpwKLJfUCFwIFgIi4MiIel3Qr8AhQBr4QERskHQ3cKKkS379ExK0Tr1r93IAwM6tVT4L4bSAPfBj4U+Bw4O3jvSkizq5jn4uBi0eUPUXa1dQsXqzPzKxWPbOYfpo+3Q1c1NhwWsNdTGZmtcZNEJKeJqMHJiKObkhEreArqc3MatTTxdRT9bwb+B/AwY0JpzVyyXiHmZlVGXewOSK2VD2ei4hLSa5daBvuYjIzq1VPF9PxVS9zJC2Keu9lfUDwYn1mZrXqOdH/bdXzIvAM8I6GRNMiXqzPzKxWPbOYTmtGIK3kxfrMzGrV08V03ljbI+IzUxdOq/g6CDOzkeqdxfQa4Kb09VuA+0nWZmoLOYGvpTYz21c9CWIpcHxE7ASQ9L+Bb0XEOY0MrJncxWRmVquexfoOAYaqXg+lZW3D94MwM6tVTwvii8D9km4kuWTgbSS3E20bOS/WZ2ZWo55ZTJ+Q9G3gN0jOo++NiIcaHlkTSaLsPiYzs32M2sUkabakyvLcPwBuJVnV9agmxdZUTg9mZvsaawziVmAZgKSXAv8OHE1yC9BPNj605vEd5czMao2VIA6KiMpU1nOB6yPiD0nuE91eazHJazGZmY00VoKoPmO+HvgOQEQMkdwBrm0INyDMzEYaa5D6EUmXAM8BLwVuB5C0sBmBNVMu5yupzcxGGqsF8X5gM8k4xBsjoj8tXw5c0uC4msrLfZuZ1Rq1BRERu4GaweiI+B7wvUYG1XQeozYzq1HPldRtz7OYzMxqOUHgLiYzsyxOEKR3lGt1EGZm00w994N4OfAR4Mjq/SPi9Q2Mq6ly8mJ9ZmYj1bNY31eBK4HPA6V6P1jS1cCbgY0R8cpR9jkVuBQoAJsjYlVavhr4LMnSHl+IiIZeuZ10MTXyCGZmB556EkQxIv5hEp99LfA5ktVga6TXU/w9sDoifibpRWl5HrgCeAPQCzwg6aaI+OEkYqiP1LCPNjM7UNUzBnGzpD+QdKikgyuP8d4UEWuBF8bY5V3ADRHxs3T/jWn5CcCTEfFUetX2V0iWGG+YSnpwN5OZ2V71tCDOTX9+pKosSBbu2x8vBwqS/g2YB3w2Ir4IHAY8W7VfL/Da0T5E0hpgDcARRxwxqUByaQsiwo0JM7OKeu4H0ajlvTuAXwP+CzAL+HdJ35/oh0TEVcBVAD09PZNqAlSSQjmCHM4QZmZQXwsCSa8kWWKju1KWftvfH73AlojYBeyStBY4Li0/vGq/pSTrQTXMni6mRh7EzOwAM+4YhKQLgcvTx2nAp4G3TsGxvwGcIqlD0mySbqTHgQeAl0k6SlIncBZw0xQcb1S53N4uJjMzS9TTgjiT5Jv9QxHxXkmHAF8e702SrgdOBRZL6gUuJJnOSkRcGRGPS7oVeIRk+fAvRMSG9L0fBm4jmeZ6dUQ8NuGaTYKvpjYz26ueBLE7IsqSipLmAxvZtwsoU0ScXcc+FwMXZ5TfAtxSR2xTwgPTZma16kkQ69JrFj4PPAj0kdx+tG1Uz2IyM7NEPbOY/iB9emXaJTQ/Ih5pbFjNVWlAuIvJzGyvegapJekcSRdExDPANkknND605ql0MTk9mJntVc+V1H8PnARUxhR2kiyF0Tb2djE5RZiZVdQzBvHaiDhe0kMAEbE1nX7adrxgn5nZXvW0IIbTBfQCQNISkmmpbUNpC+KFXUNuRZiZpepJEJcBNwIvkvQJ4D7grxsaVZOl18lx2iX/xj/d93RrgzEzmybGTRAR8c/AnwN/AzwP/LeI+GqjA2um6ssgvvPDX7YsDjOz6WTUMYgRS3pvBK6v3hYRYy3lfUBR1ZVy7mAyM0uMNUi9mWThvGL6uvqL9lQs9z1t5EbWzMzMxkwQl5EszvddktbDfdGuI7j7tCDas4pmZhM16hhERPwJsJLkntS/DTwk6dOSGnV/iJbZpwHh/GBmBowzSB2Ju0kGqa8E3gv812YE1ky5qhZEyRnCzAwYe5B6Dsm9oN8JLAFuAH6tcg/pdlK9muvOgeLoO5qZzSBjjUFsBJ4AvpL+DKBHUg9ARNzQ+PCao7qLafvu4ZbFYWY2nYyVIL5KkhRekT6qBUmLoi1UdzFt7x8mIvaZ+mpmNhONmiAi4neaGEdrVeWCoVKZbf3DHDSnLZebMjOrWz1LbbS9kW2F57cPtCQOM7PpxAmiyksWdAPwix27WxyJmVnr1XPDoK56yg5k2/qTgenjDl8IuAVhZgb1tSCy7j/dVvek/uWOJCG88rAF5AS/cIIwMxvzOogXA4cBsyS9mr1d9fOB2U2IrWle6B8C4CULu1kyr8sJwsyMsae5/ibwO8BS4DNV5TuBv2hgTE33kd98BYVcjtNfeShfuPdptuwaanVIZmYtN9Y01+uA6yS9PSK+1sSYmu7QBbP41JkrAFg0t4stfYMtjsjMrPXqGYO4U9JnJK1LH38racF4b5J0taSNkjaMsv1USdslrU8fF1Rte0bSo2n5ugnUZ78tntvJ5j63IMzM6kkQ/0TSrfSO9LEDuKaO910LrB5nn3sjYmX6+KsR205Ly3vqONaUWTK3i819g743tZnNeGONQVT8SkS8ver1RZLWj/emiFgradlkA2uVRXM7GSyW6RssMq+70OpwzMxapp4WxG5Jp1ReSDoZmKoryU6S9LCkb0s6tqo8gNslPShpzVgfIGlNpftr06ZN+x3Q4rnJJR4PPNM2d1Q1M5uUehLEB4Er0nGBnwKfA35/Co79A+DIiDgOuBz4etW2UyLieOB04EOSXjfah0TEVRHRExE9S5Ys2e+gfvXQ+RTy4s/+9WGv7GpmM9q4CSIi1qcn8RXAqyLi1RHxyP4eOCJ2RERf+vwWoCBpcfr6ufTnRuBG4IT9PV69fvXQ+fzr75/E1v5hvv7Qc806rJnZtFPPUhsLJH0GuAu4q95ZTHV87ouVrqkt6YQ0li2S5kial5bPAd4IZM6EapSVhy9kfncHT27sa+ZhzcymlXq6mK5mErOYJF1PsiTHKyT1SnqfpA9I+kC6y5nABkkPA5cBZ0UydegQ4L60/H7gWxFx60Qrtj8kcdSSuTz63HZufKiXu370S076mzvZ3u8uJzObOTTedE5J6yNi5Xhl00FPT0+sWzc1l0188MsP8u0Nv9in7KDZBe7+n6eycHbj7hUxXCrTN1CkWA66CjnmdXVk3rxoqFimHEFXR45iORgslhkcLnHwnE4kERHsHi6RkyiVg59v283hB89Ggq6OPDsHhsnnxKxCnp2DRXYNFnnx/O5Rj1UqB7M68/uUV26stGnnIMOlMocu6KZUDoZLwVCxzFCpTCGvPb+vcjkoR7C1f5iDZhfoHy4xp7ODfC6JtxxQKgc5wdb+YRbP7Rz1xk0DwyV2D5WY09VBZ0f295y+wSJz0pi39g+ze7jE4rmddHXka/YdKiaxjnejqFI5EJDL1XdDqXI56t53qpTLwea+QRbMLmTWtVqpHORHxFdd1or4rbkkPTja5QT1THPdLemUiLgv/bCpnMU0bb30RXNryrb2D3PpHU8wMFzi429ezrceeZ7P3vkEv/Kiuczr7uCc1x5JZ4e4+rvPML+7wCsOmcszW/qZ29XB1v4hymky/vm2AXYNFtk1VGLnwDAD6Yl8++5hBovlmuN2duQo5ET/cAlIFsUqp3k9n0sSQEVHTpTTk+1oOvM5hkrJcXLa+1md+RyliOQkqOROewKK6Q5dHbk9n105ZmdHjqE0Zgmyvm/M6cwzXAqK5TJdHXl2p/WoHD/Ifl9XR46OnJITVCT7VQwMl/bEVciLckA5gryS/XOCgeHkpD9c2vvOQl50F/J76lUsJUmrWA468zkK+bFPhgNpXWcX8mncye8jiD11kEjikNg5WEzqMEriCUb/hyrkk/pXEn7sfdOe55UveDlpz2ppw6UyA8NJnN2FHLk0lsouA8Uyszvz9A+VGCqW6S7k6C7kifR32DdYZF5XBxGwa6jIrMLYSWYkSeTTf4MgSTIja1n5bVSOWUp/jzklf4eVRF1VLRvDorld3HHeqin/3HpaECuB64AFJP9WLwDnTsVA9VSbyhZE/1CRpzbt4nevfYCNOwd5+/FL+eYjP888gQPM7+5gx0Axc5uUnFAq38APXTCLed0dzO7MM6+7kP7nDObPKjCvq4O53R105MRgsczOgSK7h0sUS8GcruT9EcnJo9Ah+gaKdBfydHXk6OzIsXHn4J6TJECxVGZOVweHLujm6c276Mzn6BsscvCcTsoBfYPDLJzVSS4nNu4YoCMv8rkckSaKgD3fwncOFslJ+5yEdw+VmD+rwKxCnm39Q2lcOQr5JJ6tu4bY0jdId2ceIQaLJRbP7WKoWCYnMVwq70lG+aoTe2dHEmepvDdhieQkB8mJb/Hcrj2JNp+eAEvl5GQTAXO7OugfKtGZFwtmd9KREz/fvpuhYpmIJJl25HPkBLMKefqGipRKY/9/6CrkEGLXUHFPApWSk2IyoJb8+1Tint/dQTHjBLnP30dGWbC35Tbybyl5z97fReVvohx7f09LD5rFrsEiOwaG0217k1ghLwaGkyQxqzPPrsEig+m/B8Dszjw7B4pJC7Mzv+cLTL0n6kqyrrQGq0/2lVir67P37yn5clP5wrFPUrQxzenq4KOrj5nUe/erBRER64HjJM1Pi3YBZwHTLkFMpdmdHbzysAW8/zeO5o7Hf8n5px9DENzwg70zm1a9fAnvOelIhkvBSb+yiK892MucrjxvWP5ierf2c9DsThbOLlAqR0O7pczMGmHUFkSaED5EsuT3N4A70td/BjwSEW9rVpD1msoWRJbNfYN8/6ktvGbZwRw8p5NC3jfkM7MD22RbEF8CtpLMRHo/8JckreEz0lbFjLN4bhdvXvGSVodhZtYUYyWIoyPiVQCSvgA8DxwREb6bjpnZDDBWH8meSf8RUQJ6nRzMzGaOsVoQx0nakT4Xya1Hd6TPIyLmj/5WMzM70I11R7mJTX42M7O24mk4ZmaWyQnCzMwyOUGYmVkmJwgzM8vkBGFmZpmcIMzMLJMThJmZZXKCMDOzTE4QZmaWyQnCzMwyOUGYmVkmJwgzM8vkBGFmZpmcIMzMLJMThJmZZXKCMDOzTA1LEJKulrRR0oZRtp8qabuk9enjgqptqyX9WNKTks5vVIxmZja6RrYgrgVWj7PPvRGxMn38FYCkPHAFcDqwHDhb0vIGxmlmZhkaliAiYi3wwiTeegLwZEQ8FRFDwFeAt01pcGZmNq5Wj0GcJOlhSd+WdGxadhjwbNU+vWlZJklrJK2TtG7Tpk2NjNXMbEZpZYL4AXBkRBwHXA58fTIfEhFXRURPRPQsWbJkSgM0M5vJWpYgImJHRPSlz28BCpIWA88Bh1ftujQtMzOzJmpZgpD0YklKn5+QxrIFeAB4maSjJHUCZwE3tSpOM7OZqqNRHyzpeuBUYLGkXuBCoAAQEVcCZwIflFQEdgNnRUQARUkfBm4D8sDVEfFYo+I0M7NsSs7J7aGnpyfWrVvX6jDMzA4Ykh6MiJ6sba2exWRmZtOUE4SZmWVygjAzs0xOEGZmlskJwszMMjlBmJlZJicIMzPL5ARhZmaZnCDMzCyTE4SZmWVygjAzs0xOEGZmlskJwszMMjlBmJlZJicIMzPL5ARhZmaZnCDMzCyTE4SZmWVygjAzs0xOEGZmlkkR0eoYpoykTcBPJ/n2xcDmKQznQOA6zwyu88ww2TofGRFLsja0VYLYH5LWRURPq+NoJtd5ZnCdZ4ZG1NldTGZmlskJwszMMjlB7HVVqwNoAdd5ZnCdZ4Ypr7PHIMzMLJNbEGZmlskJwszMMs34BCFptaQfS3pS0vmtjmeqSLpa0kZJG6rKDpb0HUlPpD8PSssl6bL0d/CIpONbF/nkSTpc0t2SfijpMUl/nJa3bb0ldUu6X9LDaZ0vSsuPkvQfad3+r6TOtLwrff1kun1ZK+PfH5Lykh6S9M30dVvXWdIzkh6VtF7SurSsoX/bMzpBSMoDVwCnA8uBsyUtb21UU+ZaYPWIsvOBOyPiZcCd6WtI6v+y9LEG+IcmxTjVisCfRcRy4ETgQ+m/ZzvXexB4fUQcB6wEVks6EfgU8HcR8VJgK/C+dP/3AVvT8r9L9ztQ/THweNXrmVDn0yJiZdX1Do39246IGfsATgJuq3r9MeBjrY5rCuu3DNhQ9frHwKHp80OBH6fP/xE4O2u/A/kBfAN4w0ypNzAb+AHwWpIrajvS8j1/58BtwEnp8450P7U69knUdWl6Qnw98E1AM6DOzwCLR5Q19G97RrcggMOAZ6te96Zl7eqQiHg+ff4L4JD0edv9HtJuhFcD/0Gb1zvtalkPbAS+A/wE2BYRxXSX6nrtqXO6fTuwqLkRT4lLgT8HyunrRbR/nQO4XdKDktakZQ392+6YbKR2YIuIkNSWc5wlzQW+BvxJROyQtGdbO9Y7IkrASkkLgRuBY1ocUkNJejOwMSIelHRqq+NpolMi4jlJLwK+I+lH1Rsb8bc901sQzwGHV71empa1q19KOhQg/bkxLW+b34OkAkly+OeIuCEtbvt6A0TENuBuku6VhZIqXwCr67Wnzun2BcCWJoe6v04G3irpGeArJN1Mn6W960xEPJf+3EjyReAEGvy3PdMTxAPAy9LZD53AWcBNLY6pkW4Czk2fn0vSR18pf0868+FEYHtVs/WAoaSp8E/A4xHxmapNbVtvSUvSlgOSZpGMuTxOkijOTHcbWefK7+JM4K5IO6kPFBHxsYhYGhHLSP7P3hUR76aN6yxpjqR5lefAG4ENNPpvu9UDL61+AL8F/H+Sftu/bHU8U1iv64HngWGS/sf3kfS73gk8AdwBHJzuK5LZXD8BHgV6Wh3/JOt8Ckk/7SPA+vTxW+1cb2AF8FBa5w3ABWn50cD9wJPAV4GutLw7ff1kuv3oVtdhP+t/KvDNdq9zWreH08djlXNVo/+2vdSGmZllmuldTGZmNgonCDMzy+QEYWZmmZwgzMwskxOEmZllcoIwmwBJpXQ1zcpjylYAlrRMVavvmrWal9owm5jdEbGy1UGYNYNbEGZTIF2r/9Ppev33S3ppWr5M0l3pmvx3SjoiLT9E0o3pfRwelvTr6UflJX0+vbfD7enV0WYt4QRhNjGzRnQxvbNq2/aIeBXwOZLVRgEuB66LiGN7tywAAAEOSURBVBXAPwOXpeWXAfdEch+H40mujoVk/f4rIuJYYBvw9gbXx2xUvpLabAIk9UXE3IzyZ0hu3PNUumDgLyJikaTNJOvwD6flz0fEYkmbgKURMVj1GcuA70Ry8xckfRQoRMT/aXzNzGq5BWE2dWKU5xMxWPW8hMcJrYWcIMymzjurfv57+vx7JCuOArwbuDd9fifwQdhzw58FzQrSrF7+dmI2MbPSu7dV3BoRlamuB0l6hKQVcHZa9ofANZI+AmwC3puW/zFwlaT3kbQUPkiy+q7ZtOExCLMpkI5B9ETE5lbHYjZV3MVkZmaZ3IIwM7NMbkGYmVkmJwgzM8vkBGFmZpmcIMzMLJMThJmZZfpP3KLreB4ieqcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluate the linear regression model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'timestamp': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'open': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'high': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'low': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'close': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'volume': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float32>, 'SlowD': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'SlowK': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'RSI': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'AroonDown': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'AroonUp': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.4531 - root_mean_squared_error: 1.5662\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.453098773956299, 1.5662370920181274]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KK0WMf9xPDW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8c29ebcc-9179-46ee-b013-df58022fe016"
      },
      "source": [
        "# make a prediction and compare to true value\n",
        "\n",
        "validation_features = {name:np.array(value) for name, value in validation_df.items()}\n",
        "\n",
        "print(validation_features)\n",
        "\n",
        "predictions = my_model.predict(validation_features)\n",
        "\n",
        "print(predictions)\n",
        "\n",
        "# model only doing all positive or all negative for all predictions"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'timestamp': array(['2019-04-25', '2000-09-27', '2016-05-24', '2002-02-26',\n",
            "       '2005-04-04', '2018-08-14', '2002-11-22', '2014-09-12',\n",
            "       '2009-04-24', '2008-06-03', '2012-10-05', '2011-10-05',\n",
            "       '2013-06-07', '2006-03-28', '2001-01-23', '2000-08-22',\n",
            "       '2019-01-15', '2001-01-10', '2014-05-23', '2004-07-02',\n",
            "       '2013-10-29', '2016-10-27', '2020-01-13', '2017-06-21',\n",
            "       '2005-11-14', '2015-11-12', '2003-11-26', '2014-08-01',\n",
            "       '2009-11-18', '2009-08-06', '2002-02-04', '2001-04-25',\n",
            "       '2006-10-31', '2003-10-03', '2001-08-23', '2009-03-06',\n",
            "       '2016-01-27', '2003-09-24', '2005-02-18', '2014-11-05',\n",
            "       '2001-04-03', '2001-07-19', '2012-11-26', '2005-03-28',\n",
            "       '2005-03-08', '2012-03-13', '2016-02-10', '2000-07-25',\n",
            "       '2005-03-31', '2003-10-02', '2006-12-07', '2002-04-16',\n",
            "       '2016-11-07', '2013-08-21', '2000-03-17', '2005-02-08',\n",
            "       '2019-04-12', '2003-08-27', '2000-03-08', '2006-09-28',\n",
            "       '2019-07-11', '2000-01-27', '2006-02-27', '2000-11-16',\n",
            "       '2011-02-09', '2004-01-14', '2016-02-26', '2008-03-11',\n",
            "       '2014-06-30', '2019-09-25', '2001-05-10', '2006-03-16',\n",
            "       '2017-10-12', '2004-10-08', '2015-05-11', '2006-04-28',\n",
            "       '2019-07-22', '2018-10-11', '2012-05-09', '2013-09-26',\n",
            "       '2000-06-15', '2000-02-23', '2000-03-23', '2019-08-06',\n",
            "       '2002-09-09', '2016-02-18', '2014-07-24', '2000-05-19',\n",
            "       '2005-06-10', '2004-07-06', '2013-12-02', '2007-07-19',\n",
            "       '2013-09-24', '2015-11-17', '2017-02-22', '2009-06-18',\n",
            "       '2020-05-18', '2005-11-16', '2019-07-10', '2008-11-14',\n",
            "       '2017-04-18', '2009-11-04', '2005-08-11', '2015-01-05',\n",
            "       '2009-01-09', '2011-08-04', '2002-06-28', '2009-01-22',\n",
            "       '2007-11-19', '2003-02-10', '2015-09-21', '2018-10-02',\n",
            "       '2001-06-12', '2013-05-09', '2002-01-04', '2018-01-05',\n",
            "       '2008-04-10', '2017-04-11', '2006-08-29', '2010-01-12',\n",
            "       '2014-11-24', '2014-04-22', '2004-04-16', '2015-08-20',\n",
            "       '2003-12-01', '2006-05-19', '2017-02-09', '2003-03-14',\n",
            "       '2003-03-13', '2001-06-20', '2004-10-01', '2009-03-25',\n",
            "       '2018-05-22', '2008-02-14', '2018-10-09', '2006-04-04',\n",
            "       '2012-03-02', '2006-05-09', '2008-04-16', '2010-08-12',\n",
            "       '2004-04-07', '2019-12-11', '2018-04-12', '2020-06-26',\n",
            "       '2005-08-09', '2013-01-25', '1999-12-17', '2010-09-03',\n",
            "       '2019-02-15', '2003-03-11', '2005-06-02', '2017-02-10',\n",
            "       '2000-02-07', '2018-11-06', '2016-12-23', '2015-07-30',\n",
            "       '2002-04-04', '2016-02-03', '2011-11-14', '2010-02-16',\n",
            "       '2002-02-08', '2003-11-11', '2012-06-06', '2019-11-12',\n",
            "       '2004-10-12', '2000-03-09', '2009-10-26', '2000-02-24',\n",
            "       '2005-10-25', '2008-09-29', '2004-04-02', '2007-02-28',\n",
            "       '2020-04-23', '2019-10-07', '2003-10-29', '2015-05-06',\n",
            "       '2003-04-22', '2014-10-23', '2000-08-04', '2019-02-08',\n",
            "       '2010-11-12', '2010-04-15', '2003-01-17', '2002-04-02',\n",
            "       '2017-08-23', '2016-04-18', '2017-02-06', '2004-12-21',\n",
            "       '2020-07-13', '2011-05-24', '2018-07-24', '2019-01-25',\n",
            "       '2010-10-13', '2012-10-03', '2000-03-01', '2016-12-21',\n",
            "       '2005-05-24', '2019-03-20', '2006-08-16', '2018-08-20',\n",
            "       '2007-04-10', '2014-10-21', '2009-01-21', '2017-04-17',\n",
            "       '2014-09-04', '2010-01-20', '2015-07-10', '2014-04-16',\n",
            "       '2012-08-20', '2012-08-27', '2001-02-21', '2018-08-07',\n",
            "       '2008-01-15', '2002-05-09', '2018-04-27', '2003-09-03',\n",
            "       '2018-11-27', '2017-11-16', '2003-07-08', '2019-01-23',\n",
            "       '2020-08-24', '2013-08-30', '2019-04-17', '2007-02-27',\n",
            "       '2009-05-14', '2014-05-01', '2012-08-17', '2015-07-09',\n",
            "       '2016-12-14', '2019-09-17'], dtype=object), 'open': array([139.7 , 120.06, 146.88,  99.  ,  90.08, 143.  ,  83.95, 191.47,\n",
            "       101.17, 127.48, 211.15, 174.57, 204.85,  82.86, 109.56, 121.19,\n",
            "       120.96,  92.5 , 185.84,  87.45, 177.62, 152.82, 135.48, 155.79,\n",
            "        84.25, 134.7 ,  89.79, 190.5 , 128.05, 118.31, 108.  , 112.  ,\n",
            "        91.5 ,  91.  , 104.  ,  87.47, 122.73,  91.08,  93.75, 163.13,\n",
            "        94.6 , 105.6 , 192.45,  90.71,  91.7 , 201.72, 125.  , 113.25,\n",
            "        90.46,  89.55,  94.  ,  86.35, 153.99, 184.67, 108.25,  94.28,\n",
            "       144.26,  82.  , 103.  ,  81.85, 140.79, 118.  ,  80.  ,  99.25,\n",
            "       165.62,  89.9 , 134.51, 115.8 , 181.33, 141.74, 118.5 ,  83.43,\n",
            "       147.56,  87.43, 172.65,  83.51, 150.16, 142.62, 199.99, 190.1 ,\n",
            "       116.  , 110.5 , 115.87, 142.03,  72.45, 130.  , 193.95, 106.06,\n",
            "        74.25,  86.5 , 179.46, 115.  , 190.93, 134.22, 180.09, 106.93,\n",
            "       119.88,  85.45, 140.  ,  82.63, 170.79, 121.46,  81.93, 161.27,\n",
            "        87.05, 176.5 ,  71.35,  89.83, 104.34,  77.1 , 145.39, 152.99,\n",
            "       116.75, 204.69, 124.05, 162.44, 117.5 , 170.65,  80.06, 129.03,\n",
            "       161.54, 192.01,  92.3 , 152.74,  90.9 ,  80.87, 176.17,  78.45,\n",
            "        75.99, 113.5 ,  85.95,  98.47, 145.52, 107.99, 148.08,  83.1 ,\n",
            "       197.1 ,  82.49, 118.21, 127.69,  93.37, 134.11, 156.75, 118.26,\n",
            "        83.4 , 204.45, 110.69, 126.22, 137.58,  75.82,  76.75, 177.37,\n",
            "       116.  , 120.7 , 167.  , 160.5 ,  99.96, 123.99, 189.17, 124.91,\n",
            "       103.  ,  90.  , 190.78, 135.87,  86.02, 106.5 , 120.61, 108.81,\n",
            "        83.08, 117.44,  93.55,  93.71, 119.57, 142.26,  89.6 , 172.9 ,\n",
            "        83.36, 162.12, 116.  , 132.34, 144.59, 130.53,  83.74, 102.  ,\n",
            "       140.7 , 151.75, 175.31,  96.59, 119.78, 168.5 , 146.7 , 132.87,\n",
            "       139.91, 209.94, 102.  , 166.25,  76.14, 140.53,  77.45, 146.37,\n",
            "        96.4 , 166.4 ,  86.35, 169.75, 191.69, 130.46, 165.66, 198.05,\n",
            "       200.69, 197.96, 109.55, 146.65, 102.04,  81.9 , 146.84,  86.24,\n",
            "       118.38, 147.73,  86.09, 131.37, 123.79, 182.75, 137.37,  96.  ,\n",
            "       101.72, 196.31, 201.08, 165.34, 168.37, 142.48]), 'high': array([139.75  , 120.31  , 148.75  ,  99.19  ,  90.62  , 143.82  ,\n",
            "        85.17  , 191.6   , 101.58  , 129.    , 211.79  , 177.2961,\n",
            "       206.35  ,  83.39  , 109.94  , 122.19  , 121.93  ,  94.94  ,\n",
            "       186.14  ,  87.55  , 182.32  , 154.06  , 136.64  , 155.79  ,\n",
            "        85.    , 134.7   ,  90.09  , 191.5   , 128.35  , 118.4   ,\n",
            "       108.    , 114.85  ,  92.68  ,  91.95  , 104.7   ,  88.25  ,\n",
            "       123.37  ,  91.82  ,  94.25  , 163.54  ,  94.65  , 106.    ,\n",
            "       193.37  ,  91.63  ,  92.56  , 203.9   , 125.29  , 113.37  ,\n",
            "        91.41  ,  90.45  ,  94.43  ,  86.85  , 156.11  , 186.57  ,\n",
            "       111.69  ,  94.64  , 144.44  ,  82.53  , 106.87  ,  82.35  ,\n",
            "       141.58  , 118.44  ,  80.89  ,  99.69  , 165.97  ,  90.46  ,\n",
            "       134.92  , 116.56  , 181.93  , 143.63  , 118.9   ,  83.72  ,\n",
            "       147.89  ,  87.91  , 172.99  ,  83.62  , 151.94  , 144.19  ,\n",
            "       203.    , 191.76  , 119.    , 110.5   , 115.87  , 142.47  ,\n",
            "        74.98  , 134.    , 195.62  , 107.5   ,  75.05  ,  86.73  ,\n",
            "       179.59  , 116.48  , 191.56  , 134.82  , 181.34  , 107.53  ,\n",
            "       122.36  ,  86.58  , 141.91  ,  85.4   , 171.69  , 122.5   ,\n",
            "        82.75  , 161.27  ,  87.5   , 177.92  ,  73.62  ,  90.74  ,\n",
            "       105.39  ,  78.02  , 146.98  , 153.84  , 117.8   , 205.    ,\n",
            "       125.6   , 162.9   , 119.22  , 171.23  ,  81.48  , 131.33  ,\n",
            "       163.86  , 193.    ,  92.35  , 153.91  ,  91.36  ,  81.    ,\n",
            "       177.8   ,  79.48  ,  78.68  , 114.99  ,  86.98  ,  99.86  ,\n",
            "       146.2   , 108.5   , 148.36  ,  83.78  , 198.89  ,  83.29  ,\n",
            "       120.47  , 128.78  ,  93.58  , 134.51  , 158.98  , 118.99  ,\n",
            "        83.95  , 205.18  , 111.06  , 127.6   , 138.19  ,  76.33  ,\n",
            "        77.39  , 178.8701, 116.87  , 123.81  , 167.49  , 161.4   ,\n",
            "       101.14  , 125.4499, 189.84  , 125.23  , 105.72  ,  90.03  ,\n",
            "       194.    , 136.66  ,  86.2   , 108.    , 122.44  , 111.    ,\n",
            "        83.95  , 118.43  ,  94.55  ,  94.09  , 123.03  , 142.7   ,\n",
            "        89.94  , 174.05  ,  86.06  , 162.83  , 116.5   , 133.71  ,\n",
            "       145.77  , 131.14  ,  83.74  , 102.01  , 143.05  , 153.14  ,\n",
            "       175.98  ,  97.15  , 120.99  , 168.67  , 147.04  , 134.44  ,\n",
            "       141.48  , 211.305 , 105.5   , 167.94  ,  76.51  , 140.7   ,\n",
            "        79.28  , 147.16  ,  96.8   , 166.68  ,  91.6   , 171.3   ,\n",
            "       192.69  , 131.15  , 167.4   , 198.71  , 201.13  , 198.3   ,\n",
            "       111.5   , 147.64  , 104.64  ,  83.    , 147.25  ,  87.3   ,\n",
            "       120.04  , 149.65  ,  86.75  , 135.    , 126.06  , 182.99  ,\n",
            "       141.98  ,  96.01  , 102.71  , 196.74  , 202.    , 165.51  ,\n",
            "       169.89  , 142.48  ]), 'low': array([137.71  , 115.5   , 146.88  ,  95.99  ,  89.773 , 142.93  ,\n",
            "        83.8   , 190.57  ,  99.5   , 127.46  , 210.06  , 172.68  ,\n",
            "       204.11  ,  82.29  , 107.62  , 121.    , 120.82  ,  91.69  ,\n",
            "       185.3101,  86.6   , 177.5   , 152.02  , 135.07  , 153.39  ,\n",
            "        84.11  , 133.01  ,  89.11  , 188.86  , 127.55  , 116.7   ,\n",
            "       105.99  , 111.99  ,  91.5   ,  90.57  , 103.    ,  83.81  ,\n",
            "       120.65  ,  89.33  ,  92.55  , 161.56  ,  90.1   , 103.1   ,\n",
            "       191.77  ,  90.62  ,  91.7   , 201.6107, 119.84  , 110.25  ,\n",
            "        90.22  ,  89.22  ,  93.5521,  85.58  , 153.84  , 184.28  ,\n",
            "       107.69  ,  94.13  , 143.7   ,  81.9   , 102.75  ,  81.72  ,\n",
            "       140.3   , 111.62  ,  79.95  ,  98.25  , 164.1   ,  89.75  ,\n",
            "       131.95  , 114.04  , 180.26  , 140.86  , 115.2   ,  82.61  ,\n",
            "       146.77  ,  86.51  , 170.86  ,  81.98  , 149.7   , 138.78  ,\n",
            "       199.06  , 189.455 , 115.87  , 108.5   , 111.62  , 139.31  ,\n",
            "        71.85  , 129.75  , 193.75  , 105.    ,  74.1   ,  85.13  ,\n",
            "       177.12  , 114.65  , 189.66  , 133.31  , 180.09  , 106.12  ,\n",
            "       119.75  ,  85.39  , 139.79  ,  79.5   , 169.83  , 121.16  ,\n",
            "        81.62  , 159.19  ,  84.25  , 171.18  ,  71.25  ,  88.11  ,\n",
            "       101.34  ,  76.45  , 144.92  , 152.5   , 115.55  , 202.72  ,\n",
            "       123.98  , 161.1   , 116.8789, 168.98  ,  80.06  , 129.    ,\n",
            "       161.06  , 191.2   ,  91.04  , 152.5   ,  90.48  ,  79.51  ,\n",
            "       175.91  ,  78.11  ,  75.31  , 111.76  ,  85.88  ,  96.09  ,\n",
            "       145.    , 105.5   , 146.93  ,  82.8   , 197.06  ,  82.405 ,\n",
            "       117.17  , 127.52  ,  92.51  , 133.67  , 156.67  , 116.26  ,\n",
            "        82.94  , 204.13  , 108.62  , 125.9001, 137.39  ,  75.2   ,\n",
            "        76.68  , 176.76  , 113.12  , 120.31  , 166.45  , 159.75  ,\n",
            "        99.5   , 122.29  , 186.85  , 124.11  , 102.61  ,  88.89  ,\n",
            "       190.02  , 135.02  ,  85.58  , 104.12  , 119.55  , 108.19  ,\n",
            "        82.71  , 109.95  ,  93.33  ,  92.47  , 119.12  , 141.22  ,\n",
            "        89.15  , 168.86  ,  82.6   , 161.54  , 114.31  , 132.19  ,\n",
            "       143.55  , 130.1902,  81.18  , 100.51  , 140.68  , 151.49  ,\n",
            "       174.38  ,  96.51  , 118.66  , 167.51  , 145.92  , 132.43  ,\n",
            "       139.78  , 209.3   , 100.06  , 165.25  ,  75.56  , 138.98  ,\n",
            "        77.35  , 146.15  ,  96.1642, 161.68  ,  86.    , 169.62  ,\n",
            "       190.06  , 128.95  , 165.515 , 195.    , 200.03  , 195.61  ,\n",
            "       107.29  , 146.35  , 101.23  ,  79.    , 145.66  ,  86.    ,\n",
            "       118.37  , 147.5   ,  85.19  , 130.31  , 123.36  , 181.51  ,\n",
            "       136.26  ,  92.88  , 100.77  , 193.15  , 200.66  , 163.7   ,\n",
            "       167.45  , 140.66  ]), 'close': array([138.63, 118.  , 148.31,  97.15,  90.32, 143.36,  84.43, 191.28,\n",
            "       100.08, 127.84, 210.59, 176.85, 206.35,  82.43, 109.06, 121.37,\n",
            "       121.73,  93.44, 185.94,  87.04, 182.12, 153.35, 136.6 , 153.79,\n",
            "        84.36, 133.04,  89.91, 189.15, 128.15, 117.38, 106.8 , 114.85,\n",
            "        92.33,  90.64, 103.  ,  85.81, 120.96,  89.4 ,  93.27, 161.82,\n",
            "        90.39, 104.  , 192.88,  91.04,  92.13, 203.78, 120.19, 112.  ,\n",
            "        91.38,  90.08,  94.23,  86.2 , 155.72, 184.86, 110.  ,  94.13,\n",
            "       144.35,  82.  , 106.25,  81.99, 141.24, 113.5 ,  80.63,  98.25,\n",
            "       164.65,  90.31, 132.03, 116.49, 181.27, 143.16, 115.2 ,  82.87,\n",
            "       147.03,  86.71, 171.12,  82.34, 149.74, 139.02, 201.23, 190.22,\n",
            "       116.81, 108.75, 115.25, 140.73,  74.5 , 132.45, 195.24, 106.44,\n",
            "        74.77,  85.7 , 177.48, 115.86, 189.97, 133.82, 181.15, 106.33,\n",
            "       121.56,  86.54, 140.47,  80.33, 170.05, 121.29,  82.66, 159.51,\n",
            "        84.7 , 171.48,  72.  ,  90.07, 102.22,  77.91, 146.48, 153.75,\n",
            "       117.25, 203.24, 125.6 , 162.49, 118.78, 170.58,  81.4 , 130.51,\n",
            "       162.15, 192.15,  92.28, 152.66,  91.01,  80.28, 177.21,  79.  ,\n",
            "        78.45, 113.09,  86.72,  97.95, 145.09, 106.13, 147.24,  83.45,\n",
            "       198.81,  83.23, 120.47, 128.3 ,  93.08, 133.76, 158.07, 117.19,\n",
            "        83.5 , 204.97, 110.  , 127.58, 138.03,  75.35,  77.35, 178.68,\n",
            "       114.12, 123.12, 166.71, 160.96, 100.84, 124.72, 187.35, 125.23,\n",
            "       104.99,  89.36, 193.99, 135.59,  86.  , 108.  , 120.11, 110.5 ,\n",
            "        83.36, 114.46,  94.2 ,  92.94, 121.35, 141.28,  89.34, 170.05,\n",
            "        85.63, 162.18, 115.87, 133.71, 143.74, 130.89,  81.3 , 100.95,\n",
            "       142.14, 152.53, 175.86,  97.02, 119.2 , 167.99, 146.38, 133.97,\n",
            "       140.37, 210.51, 100.25, 167.33,  75.81, 139.6 ,  79.09, 146.51,\n",
            "        96.46, 163.23,  91.42, 171.1 , 190.68, 130.25, 166.95, 196.4 ,\n",
            "       200.5 , 195.69, 107.51, 147.01, 101.83,  79.93, 146.48,  86.33,\n",
            "       120.03, 149.12,  86.25, 132.89, 125.68, 182.27, 139.11,  93.96,\n",
            "       101.05, 193.53, 201.22, 163.85, 168.51, 142.2 ]), 'volume': array([ 29.101  ,  59.489  ,  29.29132, 116.345  ,  37.378  ,  28.60041,\n",
            "        90.533  ,  29.01   , 101.575  ,  72.382  ,  28.584  ,  58.517  ,\n",
            "        29.534  ,  45.086  ,  98.269  ,  27.694  ,  35.075  ,  76.561  ,\n",
            "        25.629  ,  28.745  ,  89.046  ,  42.29336,  35.31   ,  39.34281,\n",
            "        39.153  ,  47.00465,  41.468  ,  51.811  ,  39.701  ,  60.031  ,\n",
            "        66.019  ,  68.585  ,  92.673  ,  74.793  ,  54.743  , 151.86   ,\n",
            "        50.25161,  75.758  ,  42.653  ,  41.03003, 133.3    , 136.445  ,\n",
            "        52.103  ,  40.889  ,  50.878  ,  48.66   ,  64.62375,  55.669  ,\n",
            "        44.186  ,  74.283  ,  43.108  ,  79.331  ,  38.04943,  35.51   ,\n",
            "        88.573  ,  35.411  ,  28.989  ,  38.341  ,  83.764  ,  45.923  ,\n",
            "        21.329  ,  83.246  ,  37.87   ,  37.397  ,  46.336  ,  55.051  ,\n",
            "        43.85699, 104.806  ,  42.238  ,  25.267  ,  79.939  ,  42.995  ,\n",
            "        32.55559,  40.9    ,  26.6103 ,  82.018  ,  40.926  ,  87.105  ,\n",
            "        37.425  ,  20.936  ,  53.863  ,  74.353  ,  64.924  ,  50.707  ,\n",
            "        57.85   ,  99.51438,  36.127  ,  64.192  ,  48.958  ,  64.081  ,\n",
            "        45.6    , 172.816  ,  30.853  ,  28.14487,  30.2054 ,  62.069  ,\n",
            "        42.076  ,  66.941  ,  25.139  , 120.237  ,  63.45465,  63.533  ,\n",
            "        45.704  ,  48.80389,  74.403  , 110.223  , 109.456  , 123.507  ,\n",
            "        95.022  ,  79.491  ,  38.24858,  30.299  ,  73.015  ,  35.423  ,\n",
            "        84.052  ,  51.62075,  91.493  ,  48.90163,  52.085  ,  80.815  ,\n",
            "        66.18779,  38.786  , 111.18   ,  40.11514,  52.349  ,  70.191  ,\n",
            "        30.9071 , 101.177  , 104.525  ,  88.283  ,  45.38   , 120.17   ,\n",
            "        22.84   ,  73.406  ,  36.424  ,  38.53   ,  37.274  ,  40.728  ,\n",
            "       193.177  ,  51.322  ,  45.373  ,  39.533  ,  56.394  , 107.501  ,\n",
            "        37.935  ,  33.589  ,  76.768  ,  51.429  ,  38.441  ,  81.192  ,\n",
            "        40.256  ,  29.3071 ,  57.795  ,  95.974  ,  17.01228,  19.9466 ,\n",
            "        59.285  ,  62.23424,  60.386  ,  67.773  ,  83.394  ,  48.412  ,\n",
            "        36.413  ,  30.465  ,  46.266  ,  63.341  ,  65.385  ,  91.12   ,\n",
            "        53.933  ,  95.867  ,  58.945  , 121.916  ,  68.816  ,  24.265  ,\n",
            "        51.807  ,  36.109  ,  95.426  ,  75.9951 ,  44.605  ,  32.498  ,\n",
            "        47.315  ,  64.253  , 173.312  ,  73.822  ,  40.35421,  65.38819,\n",
            "        26.50509,  48.418  ,  46.507  ,  46.436  ,  38.916  ,  57.074  ,\n",
            "        87.843  ,  31.923  , 108.078  ,  35.7521 ,  56.607  ,  36.495  ,\n",
            "        73.865  ,  24.997  ,  35.964  , 209.5212 , 249.05   ,  37.20218,\n",
            "        28.65   , 151.975  ,  45.38349,  85.273  ,  23.36   ,  24.988  ,\n",
            "        91.569  ,  35.088  , 116.295  , 101.301  ,  32.055  , 108.357  ,\n",
            "        49.038  ,  53.93609,  58.739  , 220.637  ,  40.70816,  27.31   ,\n",
            "       125.257  , 119.967  ,  94.451  ,  36.74   ,  25.518  ,  41.99708,\n",
            "        41.23821,  29.332  ]), 'delta': array([-1.07, -2.06,  1.43, -1.85,  0.24,  0.36,  0.48, -0.19, -1.09,\n",
            "        0.36, -0.56,  2.28,  1.5 , -0.43, -0.5 ,  0.18,  0.77,  0.94,\n",
            "        0.1 , -0.41,  4.5 ,  0.53,  1.12, -2.  ,  0.11, -1.66,  0.12,\n",
            "       -1.35,  0.1 , -0.93, -1.2 ,  2.85,  0.83, -0.36, -1.  , -1.66,\n",
            "       -1.77, -1.68, -0.48, -1.31, -4.21, -1.6 ,  0.43,  0.33,  0.43,\n",
            "        2.06, -4.81, -1.25,  0.92,  0.53,  0.23, -0.15,  1.73,  0.19,\n",
            "        1.75, -0.15,  0.09,  0.  ,  3.25,  0.14,  0.45, -4.5 ,  0.63,\n",
            "       -1.  , -0.97,  0.41, -2.48,  0.69, -0.06,  1.42, -3.3 , -0.56,\n",
            "       -0.53, -0.72, -1.53, -1.17, -0.42, -3.6 ,  1.24,  0.12,  0.81,\n",
            "       -1.75, -0.62, -1.3 ,  2.05,  2.45,  1.29,  0.38,  0.52, -0.8 ,\n",
            "       -1.98,  0.86, -0.96, -0.4 ,  1.06, -0.6 ,  1.68,  1.09,  0.47,\n",
            "       -2.3 , -0.74, -0.17,  0.73, -1.76, -2.35, -5.02,  0.65,  0.24,\n",
            "       -2.12,  0.81,  1.09,  0.76,  0.5 , -1.45,  1.55,  0.05,  1.28,\n",
            "       -0.07,  1.34,  1.48,  0.61,  0.14, -0.02, -0.08,  0.11, -0.59,\n",
            "        1.04,  0.55,  2.46, -0.41,  0.77, -0.52, -0.43, -1.86, -0.84,\n",
            "        0.35,  1.71,  0.74,  2.26,  0.61, -0.29, -0.35,  1.32, -1.07,\n",
            "        0.1 ,  0.52, -0.69,  1.36,  0.45, -0.47,  0.6 ,  1.31, -1.88,\n",
            "        2.42, -0.29,  0.46,  0.88,  0.73, -1.82,  0.32,  1.99, -0.64,\n",
            "        3.21, -0.28, -0.02,  1.5 , -0.5 ,  1.69,  0.28, -2.98,  0.65,\n",
            "       -0.77,  1.78, -0.98, -0.26, -2.85,  2.27,  0.06, -0.13,  1.37,\n",
            "       -0.85,  0.36, -2.44, -1.05,  1.44,  0.78,  0.55,  0.43, -0.58,\n",
            "       -0.51, -0.32,  1.1 ,  0.46,  0.57, -1.75,  1.08, -0.33, -0.93,\n",
            "        1.64,  0.14,  0.06, -3.17,  5.07,  1.35, -1.01, -0.21,  1.29,\n",
            "       -1.65, -0.19, -2.27, -2.04,  0.36, -0.21, -1.97, -0.36,  0.09,\n",
            "        1.65,  1.39,  0.16,  1.52,  1.89, -0.48,  1.74, -2.04, -0.67,\n",
            "       -2.78,  0.14, -1.49,  0.14, -0.28]), 'SlowD': array([40.3186, 38.5171, 31.6429, 19.0834, 57.7222, 43.3593, 58.231 ,\n",
            "       34.7454, 81.2119, 91.5186, 80.1117, 49.6406, 24.7919, 35.5634,\n",
            "       80.0694, 60.8884, 89.5642, 65.834 , 18.5785, 16.6949, 73.1413,\n",
            "       44.4779, 72.7408, 56.0881, 75.7015,  9.3511, 35.6636, 47.0403,\n",
            "       87.7957, 73.4764, 43.1409, 85.4018, 73.7264, 33.7697, 33.5188,\n",
            "       49.6335, 33.7963, 77.7798, 67.1065, 66.6231, 49.6404, 75.2127,\n",
            "       81.6396, 32.0649, 30.0868, 58.6967, 80.9585, 80.7423, 65.0616,\n",
            "       17.0486, 71.173 , 19.3182, 34.924 ,  7.848 , 73.125 , 79.4709,\n",
            "       43.6778, 40.4214, 45.1954, 31.9208, 54.032 , 59.1982, 43.2849,\n",
            "       45.8019, 92.8766, 36.6403, 85.3947, 42.3114, 23.7989, 37.3327,\n",
            "       63.6887, 80.8723, 69.3362, 83.7009, 34.6834, 57.7762, 84.2669,\n",
            "       13.3604, 28.7576, 21.0225, 66.9454, 36.3626, 86.8753, 39.2494,\n",
            "       19.4994, 38.7521, 53.9559, 65.1336,  7.9293, 16.2621, 13.1816,\n",
            "       69.3385, 51.3729,  9.7088, 74.6527, 27.4654, 22.6646, 81.7929,\n",
            "       69.6643, 18.6522, 27.4006, 47.197 , 37.9443, 38.8518, 78.9722,\n",
            "       29.987 , 33.5911, 43.0582, 44.9103, 27.5044, 62.5321, 60.0585,\n",
            "       72.2521, 80.3272, 42.2921, 77.7801, 58.3539, 14.5125, 61.8474,\n",
            "       22.943 , 19.6467, 47.2702, 51.985 , 62.1324, 73.8147, 23.8779,\n",
            "       74.5919, 30.8874, 26.611 , 21.367 , 62.1775, 77.8883, 68.1002,\n",
            "       59.5852, 39.6704, 42.935 , 70.3602, 38.2082, 50.8256, 72.0022,\n",
            "       69.7832, 58.3873, 70.8944, 11.8512, 45.0788, 86.1998, 20.8155,\n",
            "       45.5739, 71.0001, 38.3333, 63.7312, 78.2212, 49.2679, 22.6673,\n",
            "       37.9487, 18.4584, 19.342 , 68.3116, 52.6043, 45.7728, 55.3242,\n",
            "       35.5693, 13.9801, 67.4313, 58.8119, 45.472 , 22.3448, 24.9718,\n",
            "       60.552 , 47.3989, 50.9188, 26.8248, 48.8108, 36.8734, 48.9954,\n",
            "       62.1001, 84.8361, 16.9241, 62.0041, 79.166 , 74.7864, 63.3174,\n",
            "       74.4552, 21.1682, 21.6198, 63.7973, 31.0941, 48.9305, 22.8256,\n",
            "       65.5433, 52.0662, 72.3152, 95.0741, 65.1097, 17.6561, 43.616 ,\n",
            "       84.49  , 83.0415, 47.5686, 50.7596, 91.6248, 21.9096, 33.4859,\n",
            "       19.8442, 41.1812, 77.5707, 62.7511, 62.624 , 56.7055, 20.0548,\n",
            "       57.7948, 35.3418, 28.2016, 17.8358, 22.5985, 34.7311, 24.4323,\n",
            "       14.6295, 75.2104, 82.5446, 16.2011, 24.6402, 84.6406, 43.663 ,\n",
            "       43.1543, 66.526 , 49.0395, 64.7689, 91.0621, 64.509 ]), 'SlowK': array([46.3666, 37.235 , 40.5068, 24.8751, 51.1761, 18.4852, 71.3196,\n",
            "       48.458 , 76.977 , 80.9141, 79.4188, 32.4092, 13.9351, 19.7107,\n",
            "       84.8401, 49.8279, 80.1026, 60.1458, 25.7844, 17.433 , 78.3506,\n",
            "       53.4974, 83.6377, 63.727 , 77.3853, 10.7172, 55.9734, 23.1464,\n",
            "       93.4122, 68.2566, 64.6881, 81.1533, 65.3952, 57.1716, 32.3171,\n",
            "       33.3292, 41.833 , 63.1184, 72.5786, 49.4622, 34.8737, 62.2191,\n",
            "       89.656 , 50.6487,  8.4346, 81.1598, 66.9291, 82.2923, 59.7198,\n",
            "       35.1124, 88.7423, 23.115 , 21.3168,  9.4496, 76.0889, 74.6641,\n",
            "       49.3705, 26.8887, 47.4479, 45.8076, 35.4746, 44.9799, 36.5741,\n",
            "       68.2559, 95.0656, 15.9074, 83.3034, 33.6168, 36.6241, 30.236 ,\n",
            "       75.7747, 88.2145, 69.925 , 82.5603, 31.9892, 77.6394, 82.1576,\n",
            "        7.6231, 15.4246, 18.848 , 49.4052, 29.1691, 87.6598, 31.7803,\n",
            "       27.9063, 64.1248, 57.2402, 77.8391, 11.7336, 17.833 , 16.8425,\n",
            "       79.4923, 30.4315, 15.7629, 57.5721,  8.8633, 30.5689, 84.8671,\n",
            "       49.0557, 30.0471, 36.8528, 30.1038, 32.563 , 37.0993, 66.4236,\n",
            "       28.368 , 54.0952, 55.103 , 56.6002, 33.2075, 54.0913, 70.5799,\n",
            "       66.0169, 77.1921, 42.9427, 83.542 , 66.1244,  8.5613, 82.3412,\n",
            "       29.6728, 16.5439, 37.9052, 60.0333, 59.1575, 86.2275, 15.208 ,\n",
            "       78.3237, 47.6345, 18.3699, 17.526 , 81.8182, 81.0429, 67.6922,\n",
            "       80.9767, 19.492 , 47.0409, 61.7576, 49.3614, 37.9265, 67.2543,\n",
            "       83.1798, 73.4176, 79.7865, 12.0337, 35.2381, 83.4929, 29.4416,\n",
            "       59.7909, 84.9092, 34.8052, 58.2663, 71.8765, 70.7345, 40.01  ,\n",
            "       44.4132, 33.6421, 12.7697, 79.8132, 47.0734, 67.3637, 36.5364,\n",
            "       50.1072, 14.9787, 43.7658, 33.8734, 40.029 , 23.7445, 12.7375,\n",
            "       51.289 , 56.5433, 38.8732, 15.4759, 55.4391, 32.6382, 67.4299,\n",
            "       60.2186, 85.1346,  7.6162, 72.3103, 68.3544, 62.2139, 78.4775,\n",
            "       59.6015, 25.2703, 27.1435, 74.1363, 39.6885, 29.9765, 25.9809,\n",
            "       60.6927, 55.8547, 71.8489, 94.3778, 79.8933, 17.235 , 32.8473,\n",
            "       79.1246, 80.7259, 61.6531, 77.2403, 91.1076, 22.5275, 34.8099,\n",
            "       24.3697, 36.7598, 87.2335, 53.1213, 62.0865, 70.7534, 20.75  ,\n",
            "       47.7377, 58.4506, 41.8444, 26.6892, 39.4394, 52.014 , 31.7518,\n",
            "       20.2533, 87.2131, 73.5984, 16.6365, 15.9677, 89.2777, 23.9426,\n",
            "       55.1118, 88.4658, 56.2686, 61.595 , 87.8797, 48.0533]), 'RSI': array([47.8313, 36.9221, 50.3411, 32.3443, 55.2227, 45.1015, 65.2579,\n",
            "       52.4616, 63.0248, 63.7803, 68.6351, 49.0575, 41.0546, 57.3926,\n",
            "       78.7267, 63.224 , 59.1673, 58.0194, 37.6097, 38.2443, 40.7671,\n",
            "       31.2934, 64.2564, 53.7794, 64.3211, 33.6376, 51.4375, 56.9788,\n",
            "       69.4097, 73.5422, 33.0938, 70.9957, 70.06  , 54.9253, 36.5013,\n",
            "       45.1178, 32.2828, 67.3514, 57.2147, 29.4223, 51.5067, 40.449 ,\n",
            "       47.7238, 44.697 , 41.2088, 73.3481, 49.1096, 61.039 , 39.7122,\n",
            "       49.5548, 71.2582, 16.4817, 45.2741, 26.7813, 51.9392, 53.7487,\n",
            "       65.6463, 46.2016, 42.333 , 57.5859, 62.3125, 54.3411, 47.7884,\n",
            "       50.099 , 80.4547, 42.9589, 64.2159, 57.5787, 31.5479, 57.2247,\n",
            "       61.0454, 70.5618, 72.1587, 68.4031, 62.8269, 54.4321, 84.567 ,\n",
            "       38.466 , 42.2596, 51.6744, 67.537 , 37.1782, 62.8631, 41.2925,\n",
            "       43.4268, 47.7142, 76.4708, 45.1826, 40.2928, 31.7865, 43.0499,\n",
            "       72.1601, 51.9315, 25.6068, 68.5131, 54.8735, 38.5768, 62.0324,\n",
            "       69.1233, 32.5772, 29.0339, 41.3316, 61.0681, 53.8104, 66.9898,\n",
            "       46.037 , 42.5639, 58.1782, 34.8514, 41.2392, 42.8711, 63.5678,\n",
            "       53.0984, 53.0557, 54.0126, 76.6979, 53.9638, 37.7201, 73.3569,\n",
            "       56.6292, 38.7209, 44.4549, 53.6356, 35.69  , 53.2031, 35.5958,\n",
            "       69.8339, 43.0236, 38.5791, 52.8028, 51.9425, 72.4732, 48.7479,\n",
            "       56.7249, 42.213 , 52.8508, 65.539 , 50.4039, 55.0682, 59.602 ,\n",
            "       53.4962, 48.3644, 51.0185, 36.0666, 59.2108, 78.1031, 49.9236,\n",
            "       47.5047, 73.4215, 47.8208, 45.8506, 61.7554, 56.0355, 20.9323,\n",
            "       60.5773, 35.7722, 34.2453, 40.3347, 55.2219, 35.2928, 32.7791,\n",
            "       50.3643, 16.7143, 51.2961, 55.4015, 37.5824, 52.1742, 33.871 ,\n",
            "       58.0113, 47.6962, 36.1895, 26.6964, 56.5094, 49.91  , 45.8691,\n",
            "       73.2781, 62.5784, 13.4777, 57.6788, 66.7348, 60.9275, 61.5102,\n",
            "       65.0885, 44.7807, 32.8643, 64.2661, 61.8161, 55.1422, 34.9554,\n",
            "       47.2952, 57.0781, 80.    , 81.798 , 72.8414, 29.4696, 62.7518,\n",
            "       50.9039, 66.0613, 59.7211, 50.361 , 64.2362, 16.0081, 51.5754,\n",
            "       29.6057, 59.9599, 57.4793, 46.263 , 64.3529, 68.6786, 39.2753,\n",
            "       58.0145, 57.2813, 52.2046, 20.9243, 37.0232, 51.4953, 36.7188,\n",
            "       32.2356, 53.9953, 65.0314, 43.2631, 23.7714, 68.3461, 40.113 ,\n",
            "       52.6677, 56.5433, 61.2749, 37.8795, 64.9662, 60.8737]), 'AroonDown': array([ 71.4286, 100.    ,   0.    ,  92.8571,  35.7143,  50.    ,\n",
            "        42.8571,  78.5714,  57.1429,  50.    ,  57.1429,   0.    ,\n",
            "       100.    ,   0.    ,  14.2857,   0.    ,  14.2857,  21.4286,\n",
            "        85.7143, 100.    ,  50.    ,  57.1429,  50.    ,  35.7143,\n",
            "        28.5714,  92.8571,   7.1429,   0.    ,  21.4286,   0.    ,\n",
            "        85.7143,   7.1429,   0.    ,   0.    ,  92.8571,  57.1429,\n",
            "        71.4286,   7.1429,  64.2857,  35.7143,  50.    ,  64.2857,\n",
            "        64.2857,  71.4286,  42.8571,   0.    ,   0.    ,  14.2857,\n",
            "        50.    ,   0.    ,  57.1429,  85.7143,   7.1429, 100.    ,\n",
            "        28.5714,  50.    ,   7.1429,   0.    ,  78.5714,   0.    ,\n",
            "         0.    ,  14.2857,   7.1429,   0.    ,   0.    , 100.    ,\n",
            "        35.7143,   7.1429,  92.8571,   0.    ,   0.    ,  42.8571,\n",
            "        35.7143,  28.5714,   0.    ,  28.5714,   0.    , 100.    ,\n",
            "        21.4286,   7.1429,   0.    , 100.    ,   0.    , 100.    ,\n",
            "        92.8571,  78.5714,   0.    ,  78.5714, 100.    ,  92.8571,\n",
            "        85.7143,  14.2857,   7.1429,  92.8571,   7.1429,   0.    ,\n",
            "        92.8571,  14.2857,   0.    , 100.    ,  78.5714,  64.2857,\n",
            "       100.    ,  21.4286,  50.    ,  14.2857,  92.8571,   0.    ,\n",
            "        64.2857,  78.5714,  14.2857,   0.    ,  50.    ,  14.2857,\n",
            "        14.2857,  42.8571,  50.    , 100.    ,  14.2857,   0.    ,\n",
            "        92.8571,  92.8571,  21.4286, 100.    ,  71.4286, 100.    ,\n",
            "         0.    ,  92.8571, 100.    ,   7.1429,  64.2857,  21.4286,\n",
            "        14.2857,  71.4286, 100.    ,   0.    ,  21.4286,  28.5714,\n",
            "        21.4286,   0.    ,  21.4286,  64.2857,  64.2857,  92.8571,\n",
            "        92.8571,  57.1429,  14.2857,  85.7143,  64.2857, 100.    ,\n",
            "         7.1429,   0.    ,  78.5714,  78.5714,   0.    ,  92.8571,\n",
            "       100.    ,  35.7143,  14.2857, 100.    ,  57.1429,  14.2857,\n",
            "        92.8571,   0.    ,  14.2857,  71.4286,   0.    , 100.    ,\n",
            "        14.2857,  50.    ,  42.8571, 100.    ,   0.    ,  92.8571,\n",
            "        78.5714,  14.2857,   7.1429, 100.    ,  21.4286,   0.    ,\n",
            "        14.2857,  78.5714,  14.2857,  78.5714,  92.8571,   0.    ,\n",
            "        21.4286,   0.    ,  92.8571,  71.4286,   0.    ,   0.    ,\n",
            "         7.1429,   0.    , 100.    ,   7.1429,  50.    ,  50.    ,\n",
            "        42.8571,  85.7143,   0.    , 100.    ,   0.    ,  85.7143,\n",
            "        14.2857,  64.2857,  57.1429,  14.2857,  21.4286, 100.    ,\n",
            "        28.5714,  85.7143,  92.8571,  92.8571,  92.8571,   7.1429,\n",
            "         0.    , 100.    ,  78.5714,   7.1429,   0.    ,  92.8571,\n",
            "         0.    , 100.    ,  21.4286,  42.8571,  28.5714,  64.2857,\n",
            "        42.8571,   0.    ]), 'AroonUp': array([ 64.2857,   0.    ,  42.8571,  57.1429,   0.    ,  14.2857,\n",
            "       100.    ,  28.5714,  92.8571,  92.8571,  78.5714,  78.5714,\n",
            "        71.4286,  71.4286,  92.8571,  64.2857,  85.7143,  78.5714,\n",
            "         0.    ,  14.2857,  28.5714,  14.2857, 100.    ,  57.1429,\n",
            "       100.    ,   7.1429,  42.8571,  78.5714, 100.    ,  85.7143,\n",
            "         0.    ,  85.7143,  42.8571,  35.7143,   7.1429,   0.    ,\n",
            "         0.    ,  85.7143,  92.8571,   0.    ,  71.4286,   7.1429,\n",
            "         0.    ,   0.    ,  14.2857, 100.    ,  85.7143,  85.7143,\n",
            "         0.    ,  42.8571, 100.    ,   0.    ,   0.    ,   7.1429,\n",
            "        42.8571,   0.    ,  57.1429,  85.7143,  14.2857,  64.2857,\n",
            "       100.    ,  71.4286,  42.8571,  64.2857, 100.    ,  28.5714,\n",
            "       100.    ,  42.8571,   0.    ,  28.5714,  64.2857, 100.    ,\n",
            "        92.8571, 100.    ,  71.4286, 100.    , 100.    ,  64.2857,\n",
            "        64.2857,  71.4286,  71.4286,  42.8571, 100.    ,  92.8571,\n",
            "         7.1429,  50.    ,  71.4286,  14.2857,   0.    ,   7.1429,\n",
            "        57.1429, 100.    ,  85.7143,   0.    ,  85.7143,  71.4286,\n",
            "        14.2857, 100.    ,  78.5714,  50.    ,  50.    ,   0.    ,\n",
            "         0.    , 100.    ,  85.7143,  42.8571,   0.    , 100.    ,\n",
            "        14.2857,   0.    ,  92.8571, 100.    ,  28.5714,   0.    ,\n",
            "        35.7143, 100.    ,  14.2857,  78.5714, 100.    ,  64.2857,\n",
            "        71.4286,  57.1429,  42.8571,   7.1429,  28.5714,  71.4286,\n",
            "        28.5714,   0.    ,   0.    ,  35.7143,   7.1429, 100.    ,\n",
            "       100.    ,  42.8571,  78.5714,  35.7143,  64.2857,  50.    ,\n",
            "        78.5714,  92.8571,  85.7143,  35.7143,   0.    ,   7.1429,\n",
            "         0.    ,  92.8571,  64.2857,  21.4286,  92.8571,  14.2857,\n",
            "        42.8571,  21.4286,  21.4286,   0.    ,  50.    ,  50.    ,\n",
            "         0.    ,   7.1429,  28.5714,   7.1429,   0.    ,  64.2857,\n",
            "         0.    ,  85.7143,  85.7143,   7.1429,  50.    ,  35.7143,\n",
            "        71.4286,  64.2857,  21.4286,   0.    ,  57.1429,  78.5714,\n",
            "        35.7143,  92.8571, 100.    ,  14.2857,  28.5714,  92.8571,\n",
            "        85.7143, 100.    ,  78.5714,   7.1429,  14.2857,  35.7143,\n",
            "        50.    ,  35.7143,   0.    ,   0.    ,  85.7143,  92.8571,\n",
            "       100.    ,  92.8571,   7.1429,  64.2857,  14.2857, 100.    ,\n",
            "        21.4286,  28.5714, 100.    ,  28.5714,  35.7143,  57.1429,\n",
            "        71.4286, 100.    ,  21.4286,  78.5714, 100.    ,  64.2857,\n",
            "        85.7143,  14.2857,  14.2857,   7.1429,  50.    , 100.    ,\n",
            "        14.2857,   0.    , 100.    ,  92.8571,  42.8571,  14.2857,\n",
            "       100.    ,   0.    ,  57.1429,   7.1429, 100.    ,  28.5714,\n",
            "       100.    ,  71.4286])}\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'timestamp': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'open': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float32>, 'high': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'low': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'close': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'volume': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'delta': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'SlowD': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'SlowK': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'RSI': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'AroonDown': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'AroonUp': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "[[ 9.53350246e-01]\n",
            " [ 2.10607290e+00]\n",
            " [-1.70979872e-01]\n",
            " [-2.52494168e+00]\n",
            " [-1.14361122e-01]\n",
            " [ 1.01216912e+00]\n",
            " [-1.62601078e+00]\n",
            " [ 1.05621195e+00]\n",
            " [ 6.50186479e-01]\n",
            " [ 4.29364622e-01]\n",
            " [ 1.11890066e+00]\n",
            " [ 2.24824056e-01]\n",
            " [ 7.97871798e-02]\n",
            " [-4.01124954e-01]\n",
            " [ 2.21465632e-01]\n",
            " [ 1.60232231e-01]\n",
            " [ 9.45209324e-01]\n",
            " [-1.27981508e+00]\n",
            " [-3.84641401e-02]\n",
            " [ 9.17704999e-01]\n",
            " [-5.65624297e-01]\n",
            " [-7.50470906e-02]\n",
            " [ 5.83686650e-01]\n",
            " [ 6.91875070e-02]\n",
            " [-2.89024532e-01]\n",
            " [ 1.23312876e-01]\n",
            " [ 3.49604666e-01]\n",
            " [-6.14470065e-01]\n",
            " [ 4.61528242e-01]\n",
            " [-9.31627303e-02]\n",
            " [ 2.07501078e+00]\n",
            " [ 4.37804639e-01]\n",
            " [ 3.11385441e+00]\n",
            " [ 2.72191310e+00]\n",
            " [ 1.75554085e+00]\n",
            " [-6.67682528e-01]\n",
            " [ 1.54081213e+00]\n",
            " [-4.99115407e-01]\n",
            " [ 6.92666531e-01]\n",
            " [ 5.73512495e-01]\n",
            " [ 2.80307293e+00]\n",
            " [-2.63171005e+00]\n",
            " [-1.82459429e-01]\n",
            " [-2.70197690e-01]\n",
            " [ 9.98010099e-01]\n",
            " [-2.43973956e-01]\n",
            " [-2.13386610e-01]\n",
            " [ 5.96110523e-01]\n",
            " [-4.50186074e-01]\n",
            " [ 7.21367061e-01]\n",
            " [ 1.16416717e+00]\n",
            " [ 9.10621107e-01]\n",
            " [ 3.33509147e-01]\n",
            " [ 3.90130460e-01]\n",
            " [ 8.98312986e-01]\n",
            " [-8.88524801e-02]\n",
            " [ 1.79609165e-01]\n",
            " [-5.29968441e-01]\n",
            " [ 5.77994764e-01]\n",
            " [-3.02681208e-01]\n",
            " [ 8.36683691e-01]\n",
            " [-9.25180495e-01]\n",
            " [-1.32320538e-01]\n",
            " [-1.51903003e-01]\n",
            " [ 1.23084927e+00]\n",
            " [-2.03904621e-02]\n",
            " [ 3.32089007e-01]\n",
            " [ 7.49905765e-01]\n",
            " [ 4.30109985e-02]\n",
            " [ 1.78699359e-01]\n",
            " [ 1.45326459e+00]\n",
            " [ 1.57035515e-01]\n",
            " [-5.59511125e-01]\n",
            " [-1.39552549e-01]\n",
            " [ 2.06610978e-01]\n",
            " [ 2.08176589e+00]\n",
            " [ 1.91225216e-01]\n",
            " [-1.32548583e+00]\n",
            " [ 7.19346583e-01]\n",
            " [ 6.56372249e-01]\n",
            " [ 1.71510741e-01]\n",
            " [-4.08566706e-02]\n",
            " [ 7.82065809e-01]\n",
            " [ 9.64831769e-01]\n",
            " [-1.92267016e-01]\n",
            " [-1.22294021e+00]\n",
            " [ 8.29913557e-01]\n",
            " [ 2.89782465e-01]\n",
            " [-1.12265661e-01]\n",
            " [ 4.96388376e-01]\n",
            " [ 7.22887337e-01]\n",
            " [-3.59971449e-03]\n",
            " [ 2.43644007e-02]\n",
            " [ 1.24037191e-01]\n",
            " [ 6.86551780e-02]\n",
            " [ 3.08212304e+00]\n",
            " [ 4.55743253e-01]\n",
            " [ 6.64151728e-01]\n",
            " [ 2.41819784e-01]\n",
            " [-2.30324745e+00]\n",
            " [-5.87199509e-01]\n",
            " [ 3.16852629e-01]\n",
            " [-7.79609263e-01]\n",
            " [-6.70452535e-01]\n",
            " [ 6.14943027e-01]\n",
            " [ 4.86833990e-01]\n",
            " [ 4.86026096e+00]\n",
            " [ 2.83454359e-01]\n",
            " [ 7.16009319e-01]\n",
            " [ 1.15886605e+00]\n",
            " [ 8.83694828e-01]\n",
            " [-3.71298730e-01]\n",
            " [ 6.51897609e-01]\n",
            " [ 2.39359781e-01]\n",
            " [ 3.74097764e-01]\n",
            " [-4.57411945e-01]\n",
            " [ 7.32056350e-02]\n",
            " [ 5.04614770e-01]\n",
            " [-3.76410127e-01]\n",
            " [ 7.69780338e-01]\n",
            " [-9.53601420e-01]\n",
            " [ 4.20213193e-01]\n",
            " [ 9.21793401e-01]\n",
            " [ 1.10720038e+00]\n",
            " [ 3.79828393e-01]\n",
            " [ 8.37619364e-01]\n",
            " [-7.12114125e-02]\n",
            " [-2.14219999e+00]\n",
            " [ 3.99936922e-02]\n",
            " [ 2.52285862e+00]\n",
            " [ 2.68943965e-01]\n",
            " [ 7.47217834e-01]\n",
            " [-4.86036837e-01]\n",
            " [-9.54185277e-02]\n",
            " [ 1.67879164e+00]\n",
            " [ 6.24870546e-02]\n",
            " [ 2.64055021e-02]\n",
            " [ 4.16145205e-01]\n",
            " [ 4.74615037e-01]\n",
            " [ 4.71987307e-01]\n",
            " [ 8.41367424e-01]\n",
            " [-6.55948699e-01]\n",
            " [-5.38082831e-02]\n",
            " [ 6.40746450e+00]\n",
            " [-9.37370360e-01]\n",
            " [ 7.73431122e-01]\n",
            " [ 1.12206995e+00]\n",
            " [ 3.30492742e-02]\n",
            " [ 8.86856765e-02]\n",
            " [ 3.66851270e-01]\n",
            " [ 6.04003847e-01]\n",
            " [-2.40888909e-01]\n",
            " [-6.43194735e-01]\n",
            " [-2.16319636e-01]\n",
            " [ 9.00803983e-01]\n",
            " [-1.11703351e-01]\n",
            " [ 6.11744583e-01]\n",
            " [-1.10131815e-01]\n",
            " [ 1.95674405e-01]\n",
            " [ 7.88287938e-01]\n",
            " [ 2.61043835e+00]\n",
            " [-1.15301502e+00]\n",
            " [-5.09123623e-01]\n",
            " [ 8.18308175e-01]\n",
            " [-9.65887457e-02]\n",
            " [ 6.04175508e-01]\n",
            " [ 1.81003368e+00]\n",
            " [ 2.22331810e+00]\n",
            " [-8.14793527e-01]\n",
            " [ 1.23156235e-01]\n",
            " [-4.79989469e-01]\n",
            " [ 1.14349210e+00]\n",
            " [ 2.50661182e+00]\n",
            " [ 4.52624798e-01]\n",
            " [-4.32837307e-01]\n",
            " [ 4.21947658e-01]\n",
            " [ 1.17168272e+00]\n",
            " [ 5.51978052e-01]\n",
            " [ 4.36090715e-02]\n",
            " [ 5.24623334e-01]\n",
            " [ 9.96834219e-01]\n",
            " [-5.09263456e-01]\n",
            " [-2.48769522e+00]\n",
            " [ 1.84706938e+00]\n",
            " [ 2.16915295e-01]\n",
            " [ 4.21105087e-01]\n",
            " [-1.32770315e-01]\n",
            " [ 3.53587985e-01]\n",
            " [ 1.42001554e-01]\n",
            " [-6.59687445e-03]\n",
            " [ 1.30008817e-01]\n",
            " [-5.20400517e-02]\n",
            " [ 6.51249707e-01]\n",
            " [ 1.41859815e-01]\n",
            " [ 6.38008058e-01]\n",
            " [-2.92254806e-01]\n",
            " [-4.97874320e-01]\n",
            " [-2.76694834e-01]\n",
            " [ 6.62757576e-01]\n",
            " [ 5.04373968e-01]\n",
            " [-9.74219024e-01]\n",
            " [-2.05981255e+00]\n",
            " [ 5.81103659e+00]\n",
            " [ 1.10700774e+00]\n",
            " [ 4.97862399e-01]\n",
            " [-1.60071909e+00]\n",
            " [ 1.71634443e-02]\n",
            " [ 1.06815791e+00]\n",
            " [-2.87062228e-01]\n",
            " [-1.01802185e-01]\n",
            " [ 1.21593666e+00]\n",
            " [-4.86762449e-03]\n",
            " [-1.84572041e+00]\n",
            " [ 6.61958903e-02]\n",
            " [-1.19124845e-01]\n",
            " [-9.94827211e-01]\n",
            " [ 7.53389776e-01]\n",
            " [ 6.63896024e-01]\n",
            " [ 2.14368415e+00]\n",
            " [-6.48428631e+00]\n",
            " [ 3.79528344e-01]\n",
            " [ 2.16936752e-01]\n",
            " [ 3.62756193e-01]\n",
            " [-2.92012644e+00]\n",
            " [ 1.79789317e+00]\n",
            " [-2.26530388e-01]\n",
            " [-2.73824275e-01]\n",
            " [-7.01492012e-01]\n",
            " [ 6.51993006e-02]\n",
            " [ 3.31145465e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}